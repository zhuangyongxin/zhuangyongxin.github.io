<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JVM性能监控与故障处理工具]]></title>
    <url>%2F2019%2F05%2F21%2FJVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[引言在实际生产中，我们经常需要使用适当的监控和分析工具加快分析问题，定位解决问题。本文将介绍一些JVM中的性能监控与故障处理工具，其中大部分都是JDK自带的。采用的实验环境是Linux操作系统，JDK为openjdk 1.8.0_201。 jps：虚拟机进程状况工具jps（JVM Process Status Tool）除了名字像UNIX的ps命令之外，它的功能也和ps命令类似：可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier，LVMID）。虽然功能比较单一，但它是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到的LVMID来确定要监控的是哪一个虚拟机进程。对于本地虚拟机进程来说，LVMID与操作系统的进程ID（Process Identifier,PID）是一致的，使用Windows的任务管理器或者UNIX的ps命令也可以查询到虚拟机进程的LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名称定位时，那就只能依赖jps命令显示主类的功能才能区分了。 jsp命令格式：jps [options] [hostid]。 我们在本机上执行一下：123456/ # jps -l1 /scheduler.jar1269 sun.tools.jps.Jps/ # jps -v1 jar -Djava.security.egd=file:/dev/./urandom1302 Jps -Dapplication.home=/usr/lib/jvm/java-1.8-openjdk -Xms8m 主要选项 选项 作用 -q 仅输出VM标识符，不包括class name,jar name,arguments in main method -m 输出虚拟机进程启动时传递给主类main()函数的参数 -l 输出完全的包名，应用主类名，jar的完全路径名 -v 输出JVM参数 -V 输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 jstat：虚拟机统计信息监视工具jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 jstat命令格式为：jstat[ option vmid [interval[s|ms] [count]] ]。 对于命令格式中的VMID与LVMID需要特别说明一下：如果是本地虚拟机进程，VMID与LVMID是一致的，如果是远程虚拟机进程，那VMID的格式应当是：[protocol:][//]lvmid[@hostname[:port]/servername]。 参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每500毫秒查询一次进程3999垃圾收集状况，一共查询10次，那命令应当是： 12345678/ # jstat -gc 1 500 10 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 4096.0 4096.0 0.0 3328.0 253952.0 133671.7 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133706.1 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133706.1 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133740.6 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133740.6 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.323... 主要选项 选项 作用 -class 监视类装载、卸载数量、总空间以及类装载所耗费的时间。 -gc 监视Java堆状况，包括Eden区、两个survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息。 -gccapacity 监视内容与-gc 基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间。 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比。 -gccause 与-gcuti功能一样，但是会额外输出导致上一次GC产生的原因。 -gcnew 监视新生代GC状况。 -gcnewcapacity 监视内容与-genew基本相同，输出主要关注使用到的最大、最小空间。 -gcold 监视老年代GC状况。 -gcoldcapacity 监视内容与gcold 基本相同，输出主要关注使用到的最大、最小空间。 -gcpermcapacity 输出永久代使用到的最大、最小空间。 -compiler 输出JIT编译器编译过的方法、耗时等信息。 -printcompilation 输出已经被JIT编译的方法。 各命令显示内容含义 jstat –class \&lt;pid>：监视类装载、卸载数量、总空间以及类装载所耗费的时间。123/ # jstat -class 1Loaded Bytes Unloaded Bytes Time 12551 24437.3 115 167.4 36.37 显示列名 具体描述 Loaded 装载的类的数量 Bytes 装载类所占用的字节数 Unloaded 卸载类的数量 Bytes 卸载类的字节数 Time 装载和卸载类所花费的时间 jstat -gc \&lt;pid>：监视Java堆状况，包括Eden区、两个survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息。123/ # jstat -gc 1 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 4096.0 4096.0 3344.0 0.0 253952.0 177177.3 102912.0 74365.5 77952.0 76822.8 8576.0 8301.2 4894 99.537 5 2.000 101.538 显示列名 具体描述 S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节) S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) EU 年轻代中Eden（伊甸园）目前已使用空间 (字节) OC Old代的容量 (字节) OU Old代目前已使用空间 (字节) PC Perm(持久代)的容量 (字节) PU Perm(持久代)目前已使用空间 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jstat -gccapacity \&lt;pid>：监视内容与-gc 基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间。123/ # jstat -gccapacity 1 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 16384.0 262144.0 262144.0 4096.0 4096.0 253952.0 32768.0 524288.0 102912.0 102912.0 0.0 1118208.0 77952.0 0.0 1048576.0 8576.0 4899 5 显示列名 具体描述 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量 (字节) NGC 年轻代(young)中当前的容量 (字节) S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) OGCMN old代中初始化(最小)的大小 (字节) OGCMX old代的最大容量(字节) OGC old代当前新生成的容量 (字节) OC Old代的容量 (字节) PGCMN perm代中初始化(最小)的大小 (字节) PGCMX perm代的最大容量 (字节) PGC perm代当前新生成的容量 (字节) PC Perm(持久代)的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 jstat -gcutil \&lt;pid>：监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比。123/ # jstat -gcutil 1 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 85.94 38.56 72.31 98.55 96.80 4899 99.659 5 2.000 101.660 显示列名 具体描述 S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 E 年轻代中Eden（伊甸园）已使用的占当前容量百分比 O old代已使用的占当前容量百分比 P perm代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jstat -compiler ：输出JIT编译器编译过的方法、耗时等信息。123/ # jstat -compiler 1Compiled Failed Invalid Time FailedType FailedMethod 16516 6 0 371.01 1 com/mysql/jdbc/AbandonedConnectionCleanupThread run 显示列名 具体描述 Compiled 编译任务执行数量 Failed 编译任务执行失败数量 Invalid 编译任务执行失效数量 Time 编译任务消耗时间 FailedType 最后一次编译失败的编译类型 FailedMethod 最后一个编译失败任务所在的类及方法 jinfo：Java配置信息工具info（Configuration Info for Java）的作用是实时地查看和调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显式指定的参数列表，但如果想知道未被显式指定的参数的系统默认值，除了去找资料外，就只能使用jinfo的-flag选项进行查询了（如果只限于JDK 1.6或以上版本的话，使用java-XX：+PrintFlagsFinal查看参数默认值也是一个很好的选择），jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties()的内容打印出来。这个命令在JDK 1.5时期已经随着Linux版的JDK发布，当时只提供了信息查询的功能，JDK 1.6之后，jinfo在Windows和Linux平台都有提供，并且加入了运行期修改参数的能力，可以使用-flag [+|-] name或者-flag name=value修改一部分运行期可写的虚拟机参数值。JDK 1.6中，jinfo对于Windows平台功能仍然有较大限制，只提供了最基本的-flag选项。 jinfo命令格式：jinfo [option] [pid]。 jmap：Java内存映像工具jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较“暴力”的手段：譬如-XX:+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出现之后自动生成dump文件，通过-XX:+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成dump文件，又或者在Linux系统下通过kill -3命令发送进程退出信号“吓唬”一下虚拟机，也能拿到dump文件。 jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。 和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的-dump选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。 jmap命令格式：jmap [option] [vmid]。 比如我们使用jmap生成一个正在运行的Java应用的dump快照文件，生成的文件可以用Eclipse MAT插件进行分析 jmap -dump:format=b,file=test.hprof 1 主要选项 选项 作用 -dump 生成Java堆转储快照。格式为：-dump:[live,]format=b,file=，其中live子参数说明是否只dump出存活的对象。 -finalizerinfo 显示在F-Queue中等待Finalizer线程执行finalize方法的对象。只在Linux/Solaris平台下有效。 -heap 显示Java堆详细信息，如使用哪种回收器、参数配置、分代状况等。只在Linux/Solaris平台下有效。 -histo 显示堆中对象统计信息，包括类、实例数量和合计容量。 -permstat 以ClassLoader为统计口径显示永久代内存状态。只在Linux/Solaris平台下有效 。 -F 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生成dump快照。只在Linux/Solaris平台下有效。 jstack：Java堆栈跟踪工具jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。 jstack命令格式：jstack [option] [vmid]1234567891011121314151617/ # jstack -l 1"DiscoveryClient-2" #87 daemon prio=5 os_prio=0 tid=0x00007f5fb4004000 nid=0x67 waiting on condition [0x00007f5fb9cdf000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000005d0d515b8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: - None ... 主要选项 选项 作用 -F 当正常输出的请求不被响应时，强制输出线程堆栈。 -l 除堆栈外，显示关于锁的附加信息。 -m 如果调用到本地方法的话，可以显示C/C++的堆栈。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Redis和令牌桶算法实现的集群接口限流器]]></title>
    <url>%2F2019%2F05%2F20%2F%E5%9F%BA%E4%BA%8ERedis%E5%92%8C%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%9A%84%E9%9B%86%E7%BE%A4%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[任何系统的性能都有一个上限，当并发量超过这个上限之后，可1能会对系统造成毁灭性地打击。因此在任何时刻我们都必须保证系统的并发请求数量不能超过某个阈值，限流就是为了完成这一目的。本限流器是基于Redis记录流量数据，实现对接口的精准限流，保证系统的稳定运行。 1 令牌桶算法该限流器采用流行的令牌桶算法，现简单讲解令牌桶算法的原理 1.1 简介令牌桶算法最初来源于计算机网络。在网络传输数据时，为了防止网络拥塞，需限制流出网络的流量，使流量以比较均匀的速度向外发送。令牌桶算法就实现了这个功能，可控制发送到网络上数据的数目，并允许突发数据的发送。 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。 大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌。如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。后面再产生的令牌就会从桶中溢出。最后桶中可以保存的最大令牌数永远不会超过桶的大小。 传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。 1.2 算法过程算法描述： 假如用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中（每秒会有r个令牌放入桶中）； 假设桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃； 当一个n个字节的数据包到达时，就从令牌桶中删除n个令牌（不同大小的数据包，消耗的令牌数量不一样），并且数据包被发送到网络； 如果令牌桶中少于n个令牌，那么不会删除令牌，并且认为这个数据包在流量限制之外（n个字节，需要n个令牌。该数据包将被缓存或丢弃）； 算法允许最长b个字节的突发，但从长期运行结果看，数据包的速率被限制成常量r。对于在流量限制外的数据包可以以不同的方式处理：（1）它们可以被丢弃；（2）它们可以排放在队列中以便当令牌桶中累积了足够多的令牌时再传输；（3）它们可以继续发送，但需要做特殊标记，网络过载的时候将这些特殊标记的包丢弃。 2 实现原理本限流器主要是基于令牌桶思想，并将令牌数存储到Redis中，实现在集群模式下对接口的精准限流，实现思想如下： 对于每个限流接口，记录最大存储令牌数maxPermits， 当前存储令牌数storedPermits， 添加令牌时间间隔intervalMillis， 下次请求可以获取令牌的起始时间nextFreeTicketMillis，这些信息都记录在Redis中 响应本次请求之后，动态计算下一次可以服务的时间，如果下一次请求在这个时间之前则需要进行等待。 nextFreeTicketMicros 记录下一次可以响应的时间。例如，如果我们设置QPS为1，本次请求处理完之后，那么下一次最早的能够响应请求的时间一秒钟之后。 限流器支持处理突发流量请求，突发请求允许个数就是最大存储令牌数maxPermits。例如，我们设置QPS为1，在十秒钟之内没有请求，那么令牌桶中会有10个（假设设置的maxPermits为10）空闲令牌，如果下一次请求是 10个令牌，则可以一次性获取10个令牌，因为令牌桶中已经有10个空闲的令牌。 storedPermits 就是用来表示当前令牌桶中的空闲令牌数。 对于令牌的产生有两种方式，一种是通过后台定时任务来不断产生令牌，一种是延迟生成，在每次获取令牌之前先计算在nextFreeTicketMillis到目前这个时间段内应该产生多少令牌，并更新令牌桶。本限流器采用的是后者。 3 具体实现3.1 令牌桶1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Redis令牌桶 */@Datapublic class RedisPermits implements Serializable &#123; private static final long serialVersionUID = 1L; /** * maxPermits 最大存储令牌数 */ private Long maxPermits; /** * storedPermits 当前存储令牌数 */ private Long storedPermits; /** * intervalMillis 添加令牌时间间隔 */ private Long intervalMillis; /** * nextFreeTicketMillis 下次请求可以获取令牌的起始时间，默认当前系统时间 */ private Long nextFreeTicketMillis; /** * @param permitsPerSecond 每秒放入的令牌数 * @param maxBurstSeconds maxPermits由此字段计算，最大存储maxBurstSeconds秒生成的令牌 */ public RedisPermits(Double permitsPerSecond, Integer maxBurstSeconds) &#123; if (null == maxBurstSeconds) &#123; maxBurstSeconds = 60; &#125; this.maxPermits = (long) (permitsPerSecond * maxBurstSeconds); this.storedPermits = permitsPerSecond.longValue(); this.intervalMillis = (long) (TimeUnit.SECONDS.toMillis(1) / permitsPerSecond); this.nextFreeTicketMillis = System.currentTimeMillis(); &#125; /** * redis的过期时长 * @return */ public Long expires() &#123; long now = System.currentTimeMillis(); return 2 * TimeUnit.MINUTES.toSeconds(1) + TimeUnit.MILLISECONDS.toSeconds(Math.max(nextFreeTicketMillis, now) - now); &#125; public Map&lt;String, String&gt; toMap() &#123; Map&lt;String, String&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put("maxPermits", maxPermits.toString()); resultMap.put("storedPermits", storedPermits.toString()); resultMap.put("intervalMillis", intervalMillis.toString()); resultMap.put("nextFreeTicketMillis", nextFreeTicketMillis.toString()); return resultMap; &#125; 该类主要存储了令牌桶核心的四个参数 3.2 限流器主要方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139@Slf4j@Datapublic class RateLimiter &#123; /** * 在超时时间内尝试获取&#123;tokenCount&#125;个令牌 * @param tokenCount * @param timeout * @param timeUnit * @return * @throws InterruptedException */ public boolean tryAcquire(Long tokenCount, Long timeout, TimeUnit timeUnit) throws InterruptedException&#123; if(checkTokens(tokenCount)) &#123; Long timeoutMillis = Math.max(timeUnit.toMillis(timeout), 0); Long millisToWait = tryAndGetWaitTime(tokenCount, timeoutMillis); if(millisToWait &lt;= timeoutMillis) &#123; log.info("tryAcquire for &#123;&#125;ms &#123;&#125;", millisToWait, Thread.currentThread().getName()); Thread.sleep(millisToWait); return true; &#125; &#125; return false; &#125; /** * 等待直到获取指定数量的令牌 * @param tokenCount * @return * @throws InterruptedException */ public Long acquire(Long tokenCount) throws InterruptedException &#123; long milliToWait = this.reserve(tokenCount); log.info("acquire for &#123;&#125;ms &#123;&#125;", milliToWait, Thread.currentThread().getName()); Thread.sleep(milliToWait); return milliToWait; &#125; /** * 获取令牌n个需要等待的时间 * @param tokenCount * @return */ private long reserve(Long tokenCount) &#123; if (checkTokens(tokenCount)) &#123; return reserveAndGetWaitTime(tokenCount); &#125; else &#123; return -1; &#125; &#125; /** * 预定@&#123;tokenCount&#125;个令牌并返回所需要等待的时间 * @param tokenCount * @return */ private Long reserveAndGetWaitTime(Long tokenCount)&#123; putDefaultPermits(); String script = "redis.replicate_commands() " + "local redisKey = KEYS[1] " + "local timeStrArray = redis.call('time') " + "local seconds = tonumber(timeStrArray[1]) " + "local microseconds = tonumber(timeStrArray[2]) " + "local nowMilliseconds = seconds * 1000 + math.modf(microseconds/1000) " + "local redisPermitsValues = redis.call('hmget', redisKey, 'nextFreeTicketMillis', 'maxPermits', 'storedPermits', 'intervalMillis') " + "local nextFreeTicketMillis = tonumber(redisPermitsValues[1]) " + "local maxPermits = tonumber(redisPermitsValues[2]) " + "local storedPermits = tonumber(redisPermitsValues[3]) " + "local intervalMillis = tonumber(redisPermitsValues[4]) " + "if(nowMilliseconds &gt; nextFreeTicketMillis) " + "then " + "storedPermits = math.min(maxPermits, storedPermits + math.modf((nowMilliseconds - nextFreeTicketMillis) / intervalMillis)) " + "nextFreeTicketMillis = nowMilliseconds " + "end " + "local tokenCount = tonumber(ARGV[1]) " + "local storedPermitsToSpend = math.min(tokenCount, storedPermits) " + "local freshPermits = tokenCount - storedPermitsToSpend " + "local waitMillis = freshPermits * intervalMillis " + "nextFreeTicketMillis = nextFreeTicketMillis + waitMillis " + "storedPermits = storedPermits - storedPermitsToSpend " + "redis.call('hmset', redisKey, 'nextFreeTicketMillis', nextFreeTicketMillis, 'storedPermits', storedPermits) " + "redis.call('expire', redisKey, 120) " + "return nextFreeTicketMillis - nowMilliseconds"; List&lt;String&gt; keys = Collections.singletonList(key); List&lt;String&gt; args = Collections.singletonList(tokenCount.toString()); Object obj = redisUtil.eval(script, keys, args); Long result = null; if(obj != null) &#123; result = (Long) obj; &#125; return result; &#125; /** * 判断&#123;timeout&#125;时间内能否获取&#123;tokenCount&#125;令牌，如果能获取到则预定令牌 * @param tokenCount * @return 需要等待时长 */ private Long tryAndGetWaitTime(Long tokenCount, Long timeoutMillis) &#123; putDefaultPermits(); String script = "redis.replicate_commands() " + "local redisKey = KEYS[1] " + "local timeStrArray = redis.call('time') " + "local seconds = tonumber(timeStrArray[1]) " + "local microseconds = tonumber(timeStrArray[2]) " + "local nowMilliseconds = seconds * 1000 + math.modf(microseconds/1000) " + "local redisPermitsValues = redis.call('hmget', redisKey, 'nextFreeTicketMillis', 'maxPermits', 'storedPermits', 'intervalMillis') " + "local nextFreeTicketMillis = tonumber(redisPermitsValues[1]) " + "local maxPermits = tonumber(redisPermitsValues[2]) " + "local storedPermits = tonumber(redisPermitsValues[3]) " + "local intervalMillis = tonumber(redisPermitsValues[4]) " + "if(nowMilliseconds &gt; nextFreeTicketMillis) " + "then " + "storedPermits = math.min(maxPermits, storedPermits + math.modf((nowMilliseconds - nextFreeTicketMillis) / intervalMillis)) " + "nextFreeTicketMillis = nowMilliseconds " + "end " + "local tokenCount = tonumber(ARGV[1]) " + "local timeoutMillis = tonumber(ARGV[2]) " + "local storedPermitsToSpend = math.min(tokenCount, storedPermits) " + "local freshPermits = tokenCount - storedPermitsToSpend " + "local waitMillis = freshPermits * intervalMillis " + "local actualWaitMillis = nextFreeTicketMillis + waitMillis - nowMilliseconds " + "if(actualWaitMillis &lt;= timeoutMillis) " + "then " + "nextFreeTicketMillis = nextFreeTicketMillis + waitMillis " + "storedPermits = storedPermits - storedPermitsToSpend " + "redis.call('hmset', redisKey, 'nextFreeTicketMillis', nextFreeTicketMillis, 'storedPermits', storedPermits) " + "redis.call('expire', redisKey, 120) " + "end " + "return actualWaitMillis"; List&lt;String&gt; keys = Collections.singletonList(key); List&lt;String&gt; args = Arrays.asList(tokenCount.toString(), timeoutMillis.toString()); Object obj = redisUtil.eval(script, keys, args); Long result = null; if(obj != null) &#123; result = (Long) obj; &#125; return result; &#125;&#125; 可以看到，限流器的主要方法是acquire和tryAcquire，前者是进行线程阻塞以等待令牌桶中达到所需令牌，后者是设定超时时间，并判断在超时时间内能否获取所需令牌，可以的话再进行线程阻塞等待令牌。获取由于存储在Redis中的令牌桶信息在集群环境下会有线程不同步问题，虽然采用Redis分布锁可以解决该问题，但是会造成线程阻塞，降低并发效率。而Redis运行lua脚本是原子性操作，因此本文采用lua脚本执行对令牌桶的计算和更新操作。可以看到核心方法reserveAndGetWaitTime和tryAndGetWaitTime方法都使用了lua脚本，下面简单讲解一下这两个方法的实现逻辑。 reserveAndGetWaitTime 更新令牌桶，这一步操作就是上文讲到的延迟更新令牌 计算所需令牌数与令牌桶中令牌数的插值，确定补全所需令牌数需要等待的时间 取令牌并将令牌桶数据更新到Redis tryAndGetWaitTime 同样是先更新令牌桶 计算所需令牌数与令牌桶中令牌数的插值，确定补全所需令牌数需要等待的时间 判断等待的时间是否在超时时间内，如果是的话再取令牌将令牌桶数据更新到Redis]]></content>
      <categories>
        <category>常用组件</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>限流</tag>
        <tag>令牌桶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存常用问题及解决方案]]></title>
    <url>%2F2019%2F01%2F20%2F%E7%BC%93%E5%AD%98%E5%B8%B8%E7%94%A8%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言为了应对互联网系统的海量访问，提高系统的qps，目前绝大部分系统都采用了缓存机制，避免数据库有限的IO成为系统瓶颈，极大的提升了用户体验和系统稳定性。虽然使用缓存给系统带来了质的提升，但同时也带来了一些需要注意的问题。本文将讲述缓存常见的问题及解决方案。 缓存穿透缓存穿透是指访问一个缓存中没有的数据，但是这个数据数据库中也不存在。普通思路下我们没有从数据库中拿到数据是不会触发加缓存操作的。这时如果是有人恶意攻击，大量的访问就会透过缓存直接打到数据库，对后端服务和数据库做成巨大的压力甚至宕机。 解决方案针对缓存穿透，业界主要有以下两种解决方案： 1、空值缓存这是一种比较简单的解决方案，在第一次查询的时候，如果缓存未命中，并且从数据库的也查不到数据，就将该Key和null值缓存起来，并且设置一个较短的过期时间，例如5分钟。这样就可以应对短时间内利用同一Key值进行的攻击。 2、Bloom Filter（布隆过滤器）Bloom Filter是空间效率高的概率型数据结构，用来检查一个元素是否在一个集合中。虽然其他数据结构例如Set和HashMap同样能够检查元素的存在性，但是Bloom Filter极高的空间利用率是其他结构不可比拟的，因此也特别适用于海量数据的建索。它的核心就是一个Bit Array和k个独立的哈希函数。 添加元素的时候，通过k个哈希函数找到对应于Bit Array上的k个位置，并将这k个位置置1； 查询的时候，将要查询的元素进行k个哈希函数计算，找到Bit Array上的k个位置，如果这个k个位置都为1，说明该元素可能存在，否则一定不存在。注意，这里只能说明可能存在，而是存在一定的误判率。这是由于这k个为值1的位置，有可能是其他几个元素计算后的值。误判率是Bloom Filter的一个缺陷。 这里再回到缓存穿透的解决上，我们可以将Bloom Filter放到缓存之前。在查询元素的时候，先通过Bloom filter判断元素是否存在，进而再决定是否请求缓存。 上述两种解决方案都有各自的使用场景：空值缓存可以很好的应对同一Key值的攻击，并且代码维护简单，但是如果攻击的Key值每次都不同，那么缓存中就会出现造成大量无用的空值缓存，并且由于每次攻击的Key不同，还是会穿透到数据库，起不到保护数据库的作用。而Bloom Filter则可以很好应对多个Key值的攻击。 缓存雪崩由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 缓存雪崩的英文原意是stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。造成缓存雪崩的原因通常有两个： 缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。 缓存服务发生故障挂了而不响应或者由于网络故障等原因连接超时了，造成所有的查询都落到数据库上 解决方案1、加锁排队缓存在集中失效后，将对应Key的缓存更新任务放入队列，并对Key值加分布式锁。这时候由一个线程负责监听更新队列，并逐一取出任务进行缓存更新。等待缓存更新后，解锁Key值。大量访问请求需要排队等待Key值解锁，获取更新后的缓存。这种方式可以避免大量请求到数据库，但是缺点也很明显。由于等待锁期间会有大量线程阻塞,因此也极大降低了系统的QPS。 2、交错失效时间这种方法比较简单粗暴，既然在同一时间失效会造成请求过多雪崩，那我们错开不同的失效时间，让缓存失效均匀点，即可从一定程度上避免这种问题。在缓存进行失效时间设置的时候，从某个适当的值域中随机一个时间作为失效时间即可。 3、二级缓存做二级缓存策略，L1为一级缓存，为本地缓存，这里推荐用Caffeine实现；L2为二级缓存，为缓存服务缓存。L1缓存失效时间设置为短期，L2设置失效时间较长于L1。这时候当L1失效时，可以访问L2。这样，通过二级缓存这样就可以避免一部分缓存雪崩的情况。但是，二级缓存的维护难度较大，需要设计好更新策略，提高数据一致性。 4、缓存服务高可用将缓存服务设计成高可用的，保证在个别节点、个别机器、甚至是机房宕掉的情况下，依然可以提供服务。目前Redis的哨兵模式以及Redis集群都能够实现高可用 5、服务降级如果在高可用的情况下，缓存服务还是无情的挂掉了，这时候可以通过服务熔断和降级技术，返回预设值，阻止大量请求到数据库。这里推荐使用Hytrix。 缓存击穿缓存击穿是指由于某个缓存Key的失效，造成大量并发请求直接到数据库，造成数据库的压力。缓存击穿是针对热点Key的，只有热点Key才能在同一时间造成大量并发访问。它与缓存雪崩的区别是，缓存击穿是针对单个热点Key来说，而缓存雪崩是针对大量Key的失效。 解决方案：1、加分布式锁加载数据的时候可以利用分布式锁锁住这个数据的Key，对于获取到这个锁的线程，查询数据库更新缓存，其他线程采取重试策略，这样数据库不会同时受到很多线程访问同一条数据。这种方式能够保证缓存重建过程中数据的一致性，但会造成大量线程阻塞，影响系统QPS，对于并发不大的系统来说可以采用。 2、永不过期从缓存层面来看，不设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，对Key加更新锁，并使用单独的线程去构建缓存。 3、二级缓存由于缓存击穿可以看作特殊的缓存雪崩，因此二级缓存机制同样能够解决部分缓存击穿问题。 参考资料：https://juejin.im/post/5aa8d3d9f265da2392360a37https://blog.csdn.net/bitcarmanlee/article/details/78635217https://juejin.im/post/5b849878e51d4538c77a974a]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis是单线程的为何速度这么快]]></title>
    <url>%2F2019%2F01%2F09%2FRedis%E6%98%AF%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%BA%E4%BD%95%E9%80%9F%E5%BA%A6%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[前言Redis是当前最为常用的缓存应用，是一款基于内存操作的Key-Values数据库,它具备读写性能高、支持丰富数据类型等优点。接下来我们探讨一下Redis为什么这么快以及为什么Redis是单线程的？ Redis到底有多快Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差！有兴趣的可以参考官方的基准程序测试《How fast is Redis？（https://redis.io/topics/benchmarks） 横轴是连接数，纵轴是QPS。 Redis为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；具体可参考https://juejin.im/post/5bc672296fb9a05cee1e11f2 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用 I/O 多路复用模型，非阻塞IO；（下面会简单描述一下） 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； I/O 多路复用模型多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用I/O 多路复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）。redis基于Reactor模式开发事件处理器，配合I/O多路复用 文件事件：套接字操作的抽象 I/O多路复用程序：同时监听多个套接字，并向事件分派器传送事件。 文件事件分派器：接收套接字，根据事件类型调用相应的事件处理器 事件处理器：不同的函数实现不同的事件 为什么Redis是单线程的我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。 可以参考：https://redis.io/topics/faq 但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！注意：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究）；例如我在测试服务器上查看Redis进程，然后找到该进程下的线程： ps命令的“-T”参数表示显示线程（Show threads, possibly with SPID column.）“SID”栏表示线程ID，而“CMD”栏则显示了线程名称。可以看到Redis Server有多个线程在运行。 参考资料： https://blog.csdn.net/chenyao1994/article/details/79491337 https://redis.io/topics/benchmarks https://juejin.im/post/5bc672296fb9a05cee1e11f2 https://juejin.im/post/5c15048bf265da61223a3c29 https://studygolang.com/articles/10577]]></content>
      <categories>
        <category>Redis</category>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Eureka原理详解]]></title>
    <url>%2F2018%2F12%2F24%2FSpring-Cloud-Eureka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[传统的单体平台架构会随着业务发展而变得越来越臃肿，越来越难维护，这时候微服务架构应运而生，他的理念是将庞大的单体应用进行功能拆分，形成多个微服务，各个服务间都是独立解构的，从而解决单体应用在团队开发、维护上的问题。目前，微服务架构已经广泛应用在互联网行业。在微服务框架上，Spring Cloud 可以说是当前最为流行的框架。Spring Cloud 包含了一整套的组件，涵盖微服务框架上的各个方面。由于Spring Cloud 的使用在网上都有较为全面的教程，因此，本文重点讲解常用组件的原理。为了避免读者觉得枯燥，我就从典型的电商场景来讲。 业务场景假设我们要开发一个电商平台，可以实现用户下单支付并且发货的功能。那么我们需要有一个订单服务，支付服务，库存服务、仓储服务、积分服务（实际电商平台肯定不止这几个哈），下定支付的业务流程是这样的： 查询库存服务获取商品库存 商品有库存，去订单服务下订单 下定成功后，支付服务执行支付 支付完成后，订单服务、库存服务更新状态 积分服务完成相应功能 仓储服务执行发货 Spring Cloud Eureka在上面的业务场景中，假如支付服务完成相关操作后，想要调用订单服务，库存服务执行相关更新操作，该如何调用呢？我们连订单服务、库存服务的地址都不知道。这时候，就需要用到服务注册中心了。在微服务框架中，最为重要的莫过于服务注册中心，可以理解为它是所有服务的中枢，负责服务的注册及服务间发现。有了它，微服务间才能够互相访问。而在Spring Cloud Eureka就是这样一个核心组件。 服务注册在Spring Cloud的服务治理框架中，每个服务都有一个Eureka Client组件，他们通过Rest请求的方式向注册中心Eureka Server进行注册，并将自己的服务名、主机ip、端口号等一些信息发送给注册中心，注册中心再按服务名分类组织并维护服务清单。服务在注册后，注册中心会维护一个注册表，那注册表究竟是怎么样的呢？接下来我们就看看源码 1234567public abstract class AbstractInstanceRegistry implements InstanceRegistry &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractInstanceRegistry.class); private static final String[] EMPTY_STR_ARRAY = new String[0]; private final ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt; registry = new ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt;(); ... 可以看到，如上图所示，图中这个名字叫做registry的CocurrentHashMap，就是注册表的核心结构。不了解CocurrentHashMap的话可以查看Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析，从代码中可以看到，Eureka Server的注册表直接基于纯内存，即在内存里维护了一个数据结构。各个服务的注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表。维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这是Eureka Server非常核心的一个点。搞清楚了这个，咱们再来分析一下registry这个东西的数据结构. 首先，这个ConcurrentHashMap的key就是服务名称，比如“inventory-service”，就是一个服务名称。 value则代表了一个服务的多个服务实例。 举例：“inventory-service”是可以有3个服务实例的，每个服务实例部署在一台机器上。 再来看看作为value的这个Map：Map&lt;String, Lease&gt;这个Map的key就是服务实例的idvalue是一个叫做Lease的类，它的泛型是一个叫做InstanceInfo的东东首先说下InstanceInfo，这个InstanceInfo是什么呢？ 12345678910111213141516171819202122public class InstanceInfo &#123; ... public static final int DEFAULT_PORT = 7001; public static final int DEFAULT_SECURE_PORT = 7002; public static final int DEFAULT_COUNTRY_ID = 1; // US // The (fixed) instanceId for this instanceInfo. This should be unique within the scope of the appName. private volatile String instanceId; private volatile String appName; @Auto private volatile String appGroupName; private volatile String ipAddr; private static final String SID_DEFAULT = "na"; @Deprecated private volatile String sid = SID_DEFAULT; private volatile int port = DEFAULT_PORT; private volatile int securePort = DEFAULT_SECURE_PORT; ... 通过源码可以看到，这个InstanceInfo就代表了服务实例的详细信息，比如实例id、ip地址、端口号等。而这个Lease，里面则会维护每个服务的注册时间、启动时间以及最近一次的服务续约时间（也就是发送心跳的时间） 服务获取假如订单服务或者仓储服务有一台机器奔溃了，那么如果后续继续向那台机器调用服务的话，肯定会失败的。要避免这种情况就必须要定时更新各个服务的清单，保证服务清单中的机器都是健康的。在Eureka中，每个注册到注册中心的Eureka Client都需要定时向Eureka Server发送Rest请求，获取全量的服务清单。 如果想要定时获取服务，必须保证Eureka Client中的eureka.client.fetch-registery = true，该值默认为true 如果希望修改缓存清单的更新时间，可通过修改Eureka Client中的eureka.client.registry-fetch-interval-seconds参数，默认值为30秒 说到服务获取，可以还得再提一下Eureka Server的在服务清单获取上的多级缓存机制，这是为了提高并发访问性能而设计的。 一级缓存ReadOnlyCacheMap，通过ConcurrentMapl来实现。通过定时任务，根据时间间隔responseCacheUpdateIntervalMs(默认为30秒)从ReadWriteCacheMap中加载新数据 1234567public class ResponseCacheImpl implements ResponseCache &#123; ...... private final ConcurrentMap&lt;Key, Value&gt; readOnlyCacheMap = new ConcurrentHashMap&lt;Key, Value&gt;(); private final LoadingCache&lt;Key, Value&gt; readWriteCacheMap; ...... 二级缓存ReadWriteCacheMap,通过Google的Gauva cache来实现。同样是通过定时任务，根据时间间隔responseCacheAutoExpirationInSeconds(默认为180秒)从上文讲到的registry中获取最新数据 1234567891011121314151617181920212223242526272829303132333435363738public class ResponseCacheImpl implements ResponseCache &#123; ...... private final LoadingCache&lt;Key, Value&gt; readWriteCacheMap; ...... ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) &#123; this.serverConfig = serverConfig; this.serverCodecs = serverCodecs; this.shouldUseReadOnlyResponseCache = serverConfig.shouldUseReadOnlyResponseCache(); this.registry = registry; long responseCacheUpdateIntervalMs = serverConfig.getResponseCacheUpdateIntervalMs(); this.readWriteCacheMap = CacheBuilder.newBuilder().initialCapacity(serverConfig.getInitialCapacityOfResponseCache()) .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(), TimeUnit.SECONDS) .removalListener(new RemovalListener&lt;Key, Value&gt;() &#123; @Override public void onRemoval(RemovalNotification&lt;Key, Value&gt; notification) &#123; Key removedKey = notification.getKey(); if (removedKey.hasRegions()) &#123; Key cloneWithNoRegions = removedKey.cloneWithoutRegions(); regionSpecificKeys.remove(cloneWithNoRegions, removedKey); &#125; &#125; &#125;) .build(new CacheLoader&lt;Key, Value&gt;() &#123; @Override public Value load(Key key) throws Exception &#123; if (key.hasRegions()) &#123; Key cloneWithNoRegions = key.cloneWithoutRegions(); regionSpecificKeys.put(cloneWithNoRegions, key); &#125; Value value = generatePayload(key); return value; &#125; &#125;); ...... 客户端拉取注册表： 首先从ReadOnlyCacheMap里查缓存的注册表 如果没有，就找ReadWriteCacheMap里缓存的注册表 如果还是没有，则会触发Gauva缓存的CacheLoader.load()方法，主要执行了generatePayload()方法从registry拉取数据并写入到ReadWriteCacheMap中 获取到数据后，写入ReadOnlyCacheMap中并返回 服务续约服务提供者在注册完服务后，需要维护一个心跳用来持续告诉Eureka Server我还活着，防止Eureka Server将该服务实例从可用服务列表中剔除，该动作就叫做服务续约。关于服务续约有两个重要属性（Eureka Client配置）： eureka.instance.lease-renewal-interval-in-seconds，用于定义服务续约的调用间隔时间，也就是定时发送心跳的时间，默认为30秒 eureka.instance.lease-expiration-duration-in-seconds，用于定义服务失效的时间，超过该时间没有发送心跳给Eureka Server，就会将该服务从服务列表剔除，默认为90秒 Eureka Server在启动之后会创建一个定时任务，每隔一段时间（默认为60秒）将当前服务注册表中超时（默认为90秒）没有续约的服务剔除。 接下来我们从源码中来了解服务续约的实现机制：12345678910111213141516171819202122232425@Singletonpublic class DiscoveryClient implements EurekaClient &#123; ...... private void initScheduledTasks() &#123; ...... //判断是否应该向Eureka Server注册 if (clientConfig.shouldRegisterWithEureka()) &#123; int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info("Starting heartbeat executor: " + "renew interval is: &#123;&#125;", renewalIntervalInSecs); // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( "heartbeat", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); ......&#125; 服务续约任务的初始化在DicoveryClient中，可以看到，调度线程池、续约线程池、续约间隔、HeartbeatThread全部封装在了TimedSupervisorTask中，TimedSupervisorTask相当于一个包装类或调度类，封装了续约所需要的全部信息。TimedSupervisorTask内部实现了Runnable接口。1234567891011121314151617181920212223242526272829303132333435363738394041@Singletonpublic class DiscoveryClient implements EurekaClient &#123; ...... /** * The heartbeat task that renews the lease in the given intervals. */ private class HeartbeatThread implements Runnable &#123; public void run() &#123; if (renew()) &#123; lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis(); &#125; &#125; &#125; ...... /** * Renew with the eureka service by making the appropriate REST call */ boolean renew() &#123; EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(PREFIX + "&#123;&#125; - Heartbeat status: &#123;&#125;", appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) &#123; REREGISTER_COUNTER.increment(); logger.info(PREFIX + "&#123;&#125; - Re-registering apps/&#123;&#125;", appPathIdentifier, instanceInfo.getAppName()); long timestamp = instanceInfo.setIsDirtyWithTime(); boolean success = register(); if (success) &#123; instanceInfo.unsetIsDirty(timestamp); &#125; return success; &#125; return httpResponse.getStatusCode() == Status.OK.getStatusCode(); &#125; catch (Throwable e) &#123; logger.error(PREFIX + "&#123;&#125; - was unable to send heartbeat!", appPathIdentifier, e); return false; &#125; &#125; ......&#125; 续约的具体执行逻辑在renew()方法中，实现较为简单，就是通过Rest请求向Eureka Server发送心跳。 参考资料: https://juejin.im/post/5be13b83f265da6116393fc7 https://juejin.im/post/5be3f8dcf265da613a5382ca https://blog.csdn.net/u012394095/article/details/80894140 《Spring Cloud微服务实战》-翟永超著]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Eureka</tag>
        <tag>微服务</tag>
        <tag>注册中心</tag>
      </tags>
  </entry>
</search>
