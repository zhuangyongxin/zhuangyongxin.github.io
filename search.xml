<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[缓存常用问题及解决方案]]></title>
    <url>%2F2019%2F01%2F20%2F%E7%BC%93%E5%AD%98%E5%B8%B8%E7%94%A8%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言为了应对互联网系统的海量访问，提高系统的qps，目前绝大部分系统都采用了缓存机制，避免数据库有限的IO成为系统瓶颈，极大的提升了用户体验和系统稳定性。虽然使用缓存给系统带来了质的提升，但同时也带来了一些需要注意的问题。本文将讲述缓存常见的问题及解决方案。 缓存穿透缓存穿透是指访问一个缓存中没有的数据，但是这个数据数据库中也不存在。普通思路下我们没有从数据库中拿到数据是不会触发加缓存操作的。这时如果是有人恶意攻击，大量的访问就会透过缓存直接打到数据库，对后端服务和数据库做成巨大的压力甚至宕机。 解决方案针对缓存穿透，业界主要有以下两种解决方案： 1、空值缓存这是一种比较简单的解决方案，在第一次查询的时候，如果缓存未命中，并且从数据库的也查不到数据，就将该Key和null值缓存起来，并且设置一个较短的过期时间，例如5分钟。这样就可以应对短时间内利用同一Key值进行的攻击。 2、Bloom Filter（布隆过滤器）Bloom Filter是空间效率高的概率型数据结构，用来检查一个元素是否在一个集合中。虽然其他数据结构例如Set和HashMap同样能够检查元素的存在性，但是Bloom Filter极高的空间利用率是其他结构不可比拟的，因此也特别适用于海量数据的建索。它的核心就是一个Bit Array和k个独立的哈希函数。 添加元素的时候，通过k个哈希函数找到对应于Bit Array上的k个位置，并将这k个位置置1； 查询的时候，将要查询的元素进行k个哈希函数计算，找到Bit Array上的k个位置，如果这个k个位置都为1，说明该元素可能存在，否则一定不存在。注意，这里只能说明可能存在，而是存在一定的误判率。这是由于这k个为值1的位置，有可能是其他几个元素计算后的值。误判率是Bloom Filter的一个缺陷。 这里再回到缓存穿透的解决上，我们可以将Bloom Filter放到缓存之前。在查询元素的时候，先通过Bloom filter判断元素是否存在，进而再决定是否请求缓存。上述两种解决方案都有各自的使用场景：空值缓存可以很好的应对同一Key值的攻击，并且代码维护简单，但是如果攻击的Key值每次都不同，那么缓存中就会出现造成大量无用的空值缓存，并且由于每次攻击的Key不同，还是会穿透到数据库，起不到保护数据库的作用。而Bloom Filter则可以很好应对多个Key值的攻击。 缓存雪崩由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 缓存雪崩的英文原意是stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。造成缓存雪崩的原因通常有两个： 缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。 缓存服务发生故障挂了而不响应或者由于网络故障等原因连接超时了，造成所有的查询都落到数据库上 解决方案1、加锁排队缓存在集中失效后，将对应Key的缓存更新任务放入队列，并对Key值加分布式锁。这时候由一个线程负责监听更新队列，并逐一取出任务进行缓存更新。等待缓存更新后，解锁Key值。大量访问请求需要排队等待Key值解锁，获取更新后的缓存。这种方式可以避免大量请求到数据库，但是缺点也很明显。由于等待锁期间会有大量线程阻塞,因此也极大降低了系统的QPS。 2、交错失效时间这种方法比较简单粗暴，既然在同一时间失效会造成请求过多雪崩，那我们错开不同的失效时间，让缓存失效均匀点，即可从一定程度上避免这种问题。在缓存进行失效时间设置的时候，从某个适当的值域中随机一个时间作为失效时间即可。 3、二级缓存做二级缓存策略，L1为一级缓存，为本地缓存，这里推荐用Caffeine实现；L2为二级缓存，为缓存服务缓存。L1缓存失效时间设置为短期，L2设置失效时间较长于L1。这时候当L1失效时，可以访问L2。这样，通过二级缓存这样就可以避免一部分缓存雪崩的情况。但是，二级缓存的维护难度较大，需要设计好更新策略，提高数据一致性。 4、缓存服务高可用将缓存服务设计成高可用的，保证在个别节点、个别机器、甚至是机房宕掉的情况下，依然可以提供服务。目前Redis的哨兵模式以及Redis集群都能够实现高可用 5、服务降级如果在高可用的情况下，缓存服务还是无情的挂掉了，这时候可以通过服务熔断和降级技术，返回预设值，阻止大量请求到数据库。这里推荐使用Hytrix。 缓存击穿缓存击穿是指由于某个缓存Key的失效，造成大量并发请求直接到数据库，造成数据库的压力。缓存击穿是针对热点Key的，只有热点Key才能在同一时间造成大量并发访问。它与缓存雪崩的区别是，缓存击穿是针对单个热点Key来说，而缓存雪崩是针对大量Key的失效。 解决方案：1、加分布式锁加载数据的时候可以利用分布式锁锁住这个数据的Key，对于获取到这个锁的线程，查询数据库更新缓存，其他线程采取重试策略，这样数据库不会同时受到很多线程访问同一条数据。这种方式能够保证缓存重建过程中数据的一致性，但会造成大量线程阻塞，影响系统QPS，对于并发不大的系统来说可以采用。 2、永不过期从缓存层面来看，不设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，对Key加更新锁，并使用单独的线程去构建缓存。 3、二级缓存由于缓存击穿可以看作特殊的缓存雪崩，因此二级缓存机制同样能够解决部分缓存击穿问题。 参考资料：https://juejin.im/post/5aa8d3d9f265da2392360a37https://blog.csdn.net/bitcarmanlee/article/details/78635217https://juejin.im/post/5b849878e51d4538c77a974a]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis是单线程的为何速度这么快]]></title>
    <url>%2F2019%2F01%2F09%2FRedis%E6%98%AF%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%BA%E4%BD%95%E9%80%9F%E5%BA%A6%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[前言Redis是当前最为常用的缓存应用，是一款基于内存操作的Key-Values数据库,它具备读写性能高、支持丰富数据类型等优点。接下来我们探讨一下Redis为什么这么快以及为什么Redis是单线程的？ Redis到底有多快Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差！有兴趣的可以参考官方的基准程序测试《How fast is Redis？（https://redis.io/topics/benchmarks） 横轴是连接数，纵轴是QPS。 Redis为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；具体可参考https://juejin.im/post/5bc672296fb9a05cee1e11f2 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用 I/O 多路复用模型，非阻塞IO；（下面会简单描述一下） 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； I/O 多路复用模型多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用I/O 多路复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）。redis基于Reactor模式开发事件处理器，配合I/O多路复用 文件事件：套接字操作的抽象 I/O多路复用程序：同时监听多个套接字，并向事件分派器传送事件。 文件事件分派器：接收套接字，根据事件类型调用相应的事件处理器 事件处理器：不同的函数实现不同的事件 为什么Redis是单线程的我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。 可以参考：https://redis.io/topics/faq 但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！注意：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究）；例如我在测试服务器上查看Redis进程，然后找到该进程下的线程： ps命令的“-T”参数表示显示线程（Show threads, possibly with SPID column.）“SID”栏表示线程ID，而“CMD”栏则显示了线程名称。可以看到Redis Server有多个线程在运行。 参考资料： https://blog.csdn.net/chenyao1994/article/details/79491337 https://redis.io/topics/benchmarks https://juejin.im/post/5bc672296fb9a05cee1e11f2 https://juejin.im/post/5c15048bf265da61223a3c29 https://studygolang.com/articles/10577]]></content>
      <categories>
        <category>Redis</category>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Eureka原理详解]]></title>
    <url>%2F2018%2F12%2F24%2FSpring-Cloud-Eureka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[传统的单体平台架构会随着业务发展而变得越来越臃肿，越来越难维护，这时候微服务架构应运而生，他的理念是将庞大的单体应用进行功能拆分，形成多个微服务，各个服务间都是独立解构的，从而解决单体应用在团队开发、维护上的问题。目前，微服务架构已经广泛应用在互联网行业。在微服务框架上，Spring Cloud 可以说是当前最为流行的框架。Spring Cloud 包含了一整套的组件，涵盖微服务框架上的各个方面。由于Spring Cloud 的使用在网上都有较为全面的教程，因此，本文重点讲解常用组件的原理。为了避免读者觉得枯燥，我就从典型的电商场景来讲。 业务场景假设我们要开发一个电商平台，可以实现用户下单支付并且发货的功能。那么我们需要有一个订单服务，支付服务，库存服务、仓储服务、积分服务（实际电商平台肯定不止这几个哈），下定支付的业务流程是这样的： 查询库存服务获取商品库存 商品有库存，去订单服务下订单 下定成功后，支付服务执行支付 支付完成后，订单服务、库存服务更新状态 积分服务完成相应功能 仓储服务执行发货 Spring Cloud Eureka在上面的业务场景中，假如支付服务完成相关操作后，想要调用订单服务，库存服务执行相关更新操作，该如何调用呢？我们连订单服务、库存服务的地址都不知道。这时候，就需要用到服务注册中心了。在微服务框架中，最为重要的莫过于服务注册中心，可以理解为它是所有服务的中枢，负责服务的注册及服务间发现。有了它，微服务间才能够互相访问。而在Spring Cloud Eureka就是这样一个核心组件。 服务注册在Spring Cloud的服务治理框架中，每个服务都有一个Eureka Client组件，他们通过Rest请求的方式向注册中心Eureka Server进行注册，并将自己的服务名、主机ip、端口号等一些信息发送给注册中心，注册中心再按服务名分类组织并维护服务清单。服务在注册后，注册中心会维护一个注册表，那注册表究竟是怎么样的呢？接下来我们就看看源码 1234567public abstract class AbstractInstanceRegistry implements InstanceRegistry &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractInstanceRegistry.class); private static final String[] EMPTY_STR_ARRAY = new String[0]; private final ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt; registry = new ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt;(); ... 可以看到，如上图所示，图中这个名字叫做registry的CocurrentHashMap，就是注册表的核心结构。不了解CocurrentHashMap的话可以查看Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析，从代码中可以看到，Eureka Server的注册表直接基于纯内存，即在内存里维护了一个数据结构。各个服务的注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表。维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这是Eureka Server非常核心的一个点。搞清楚了这个，咱们再来分析一下registry这个东西的数据结构. 首先，这个ConcurrentHashMap的key就是服务名称，比如“inventory-service”，就是一个服务名称。 value则代表了一个服务的多个服务实例。 举例：“inventory-service”是可以有3个服务实例的，每个服务实例部署在一台机器上。 再来看看作为value的这个Map：Map&lt;String, Lease&gt;这个Map的key就是服务实例的idvalue是一个叫做Lease的类，它的泛型是一个叫做InstanceInfo的东东首先说下InstanceInfo，这个InstanceInfo是什么呢？ 12345678910111213141516171819202122public class InstanceInfo &#123; ... public static final int DEFAULT_PORT = 7001; public static final int DEFAULT_SECURE_PORT = 7002; public static final int DEFAULT_COUNTRY_ID = 1; // US // The (fixed) instanceId for this instanceInfo. This should be unique within the scope of the appName. private volatile String instanceId; private volatile String appName; @Auto private volatile String appGroupName; private volatile String ipAddr; private static final String SID_DEFAULT = "na"; @Deprecated private volatile String sid = SID_DEFAULT; private volatile int port = DEFAULT_PORT; private volatile int securePort = DEFAULT_SECURE_PORT; ... 通过源码可以看到，这个InstanceInfo就代表了服务实例的详细信息，比如实例id、ip地址、端口号等。而这个Lease，里面则会维护每个服务的注册时间、启动时间以及最近一次的服务续约时间（也就是发送心跳的时间） 服务获取假如订单服务或者仓储服务有一台机器奔溃了，那么如果后续继续向那台机器调用服务的话，肯定会失败的。要避免这种情况就必须要定时更新各个服务的清单，保证服务清单中的机器都是健康的。在Eureka中，每个注册到注册中心的Eureka Client都需要定时向Eureka Server发送Rest请求，获取全量的服务清单。 如果想要定时获取服务，必须保证Eureka Client中的eureka.client.fetch-registery = true，该值默认为true 如果希望修改缓存清单的更新时间，可通过修改Eureka Client中的eureka.client.registry-fetch-interval-seconds参数，默认值为30秒 说到服务获取，可以还得再提一下Eureka Server的在服务清单获取上的多级缓存机制，这是为了提高并发访问性能而设计的。 一级缓存ReadOnlyCacheMap，通过ConcurrentMapl来实现。通过定时任务，根据时间间隔responseCacheUpdateIntervalMs(默认为30秒)从ReadWriteCacheMap中加载新数据 1234567public class ResponseCacheImpl implements ResponseCache &#123; ...... private final ConcurrentMap&lt;Key, Value&gt; readOnlyCacheMap = new ConcurrentHashMap&lt;Key, Value&gt;(); private final LoadingCache&lt;Key, Value&gt; readWriteCacheMap; ...... 二级缓存ReadWriteCacheMap,通过Google的Gauva cache来实现。同样是通过定时任务，根据时间间隔responseCacheAutoExpirationInSeconds(默认为180秒)从上文讲到的registry中获取最新数据 1234567891011121314151617181920212223242526272829303132333435363738public class ResponseCacheImpl implements ResponseCache &#123; ...... private final LoadingCache&lt;Key, Value&gt; readWriteCacheMap; ...... ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) &#123; this.serverConfig = serverConfig; this.serverCodecs = serverCodecs; this.shouldUseReadOnlyResponseCache = serverConfig.shouldUseReadOnlyResponseCache(); this.registry = registry; long responseCacheUpdateIntervalMs = serverConfig.getResponseCacheUpdateIntervalMs(); this.readWriteCacheMap = CacheBuilder.newBuilder().initialCapacity(serverConfig.getInitialCapacityOfResponseCache()) .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(), TimeUnit.SECONDS) .removalListener(new RemovalListener&lt;Key, Value&gt;() &#123; @Override public void onRemoval(RemovalNotification&lt;Key, Value&gt; notification) &#123; Key removedKey = notification.getKey(); if (removedKey.hasRegions()) &#123; Key cloneWithNoRegions = removedKey.cloneWithoutRegions(); regionSpecificKeys.remove(cloneWithNoRegions, removedKey); &#125; &#125; &#125;) .build(new CacheLoader&lt;Key, Value&gt;() &#123; @Override public Value load(Key key) throws Exception &#123; if (key.hasRegions()) &#123; Key cloneWithNoRegions = key.cloneWithoutRegions(); regionSpecificKeys.put(cloneWithNoRegions, key); &#125; Value value = generatePayload(key); return value; &#125; &#125;); ...... 客户端拉取注册表： 首先从ReadOnlyCacheMap里查缓存的注册表 如果没有，就找ReadWriteCacheMap里缓存的注册表 如果还是没有，则会触发Gauva缓存的CacheLoader.load()方法，主要执行了generatePayload()方法从registry拉取数据并写入到ReadWriteCacheMap中 获取到数据后，写入ReadOnlyCacheMap中并返回 服务续约服务提供者在注册完服务后，需要维护一个心跳用来持续告诉Eureka Server我还活着，防止Eureka Server将该服务实例从可用服务列表中剔除，该动作就叫做服务续约。关于服务续约有两个重要属性（Eureka Client配置）： eureka.instance.lease-renewal-interval-in-seconds，用于定义服务续约的调用间隔时间，也就是定时发送心跳的时间，默认为30秒 eureka.instance.lease-expiration-duration-in-seconds，用于定义服务失效的时间，超过该时间没有发送心跳给Eureka Server，就会将该服务从服务列表剔除，默认为90秒 Eureka Server在启动之后会创建一个定时任务，每隔一段时间（默认为60秒）将当前服务注册表中超时（默认为90秒）没有续约的服务剔除。 接下来我们从源码中来了解服务续约的实现机制：12345678910111213141516171819202122232425@Singletonpublic class DiscoveryClient implements EurekaClient &#123; ...... private void initScheduledTasks() &#123; ...... //判断是否应该向Eureka Server注册 if (clientConfig.shouldRegisterWithEureka()) &#123; int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info("Starting heartbeat executor: " + "renew interval is: &#123;&#125;", renewalIntervalInSecs); // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( "heartbeat", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); ......&#125; 服务续约任务的初始化在DicoveryClient中，可以看到，调度线程池、续约线程池、续约间隔、HeartbeatThread全部封装在了TimedSupervisorTask中，TimedSupervisorTask相当于一个包装类或调度类，封装了续约所需要的全部信息。TimedSupervisorTask内部实现了Runnable接口。1234567891011121314151617181920212223242526272829303132333435363738394041@Singletonpublic class DiscoveryClient implements EurekaClient &#123; ...... /** * The heartbeat task that renews the lease in the given intervals. */ private class HeartbeatThread implements Runnable &#123; public void run() &#123; if (renew()) &#123; lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis(); &#125; &#125; &#125; ...... /** * Renew with the eureka service by making the appropriate REST call */ boolean renew() &#123; EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(PREFIX + "&#123;&#125; - Heartbeat status: &#123;&#125;", appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) &#123; REREGISTER_COUNTER.increment(); logger.info(PREFIX + "&#123;&#125; - Re-registering apps/&#123;&#125;", appPathIdentifier, instanceInfo.getAppName()); long timestamp = instanceInfo.setIsDirtyWithTime(); boolean success = register(); if (success) &#123; instanceInfo.unsetIsDirty(timestamp); &#125; return success; &#125; return httpResponse.getStatusCode() == Status.OK.getStatusCode(); &#125; catch (Throwable e) &#123; logger.error(PREFIX + "&#123;&#125; - was unable to send heartbeat!", appPathIdentifier, e); return false; &#125; &#125; ......&#125; 续约的具体执行逻辑在renew()方法中，实现较为简单，就是通过Rest请求向Eureka Server发送心跳。 参考资料: https://juejin.im/post/5be13b83f265da6116393fc7 https://juejin.im/post/5be3f8dcf265da613a5382ca https://blog.csdn.net/u012394095/article/details/80894140 《Spring Cloud微服务实战》-翟永超著]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Eureka</tag>
        <tag>微服务</tag>
        <tag>注册中心</tag>
      </tags>
  </entry>
</search>
