<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[结合命令理解Dokcer镜像和容器原理]]></title>
    <url>%2F2019%2F07%2F05%2F%E7%BB%93%E5%90%88%E5%91%BD%E4%BB%A4%E7%90%86%E8%A7%A3Dokcer%E9%95%9C%E5%83%8F%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[这篇文章希望能够帮助读者深入理解Docker的命令，还有容器（container）和镜像（image）之间的区别，并深入探讨容器和运行中的容器之间的区别。 当我对Docker技术还是一知半解的时候，我发现理解Docker的命令非常困难。于是，我花了几周的时间来学习Docker的工作原理，更确切地说，是关于Docker统一文件系统（the union file system）的知识，然后回过头来再看Docker的命令，一切变得顺理成章，简单极了。 题外话：就我个人而言，掌握一门技术并合理使用它的最好办法就是深入理解这项技术背后的工作原理。通常情况下，一项新技术的诞生常常会伴随着媒体的大肆宣传和炒作，这使得用户很难看清技术的本质。更确切地说，新技术总是会发明一些新的术语或者隐喻词来帮助宣传，这在初期是非常有帮助的，但是这给技术的原理蒙上了一层砂纸，不利于用户在后期掌握技术的真谛。 Git就是一个很好的例子。我之前不能够很好的使用Git，于是我花了一段时间去学习Git的原理，直到这时，我才真正明白了Git的用法。我坚信只有真正理解Git内部原理的人才能够掌握这个工具。 镜像定义镜像（Image）就是一堆只读层（read-only layer）的统一视角，也许这个定义有些难以理解，下面的这张图能够帮助读者理解镜像的定义。 从左边我们看到了多个只读层，它们重叠在一起。除了最下面一层，其它层都会有一个指针指向下一层。这些层是Docker内部的实现细节，并且能够在主机（译者注：运行Docker的机器）的文件系统上访问到。统一文件系统（union file system）技术能够将不同的层整合成一个文件系统，为这些层提供了一个统一的视角，这样就隐藏了多层的存在，在用户的角度看来，只存在一个文件系统。我们可以在图片的右边看到这个视角的形式。 你可以在你的主机文件系统上找到有关这些层的文件。需要注意的是，在一个运行中的容器内部，这些层是不可见的。在我的主机上，我发现它们存于/var/lib/docker/aufs目录下。1sudo tree -L 1 /var/lib/docker//var/lib/docker/ ##容器定义容器（container）的定义和镜像（image）几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。 细心的读者可能会发现，容器的定义并没有提及容器是否在运行，没错，这是故意的。正是这个发现帮助我理解了很多困惑。 要点：容器 = 镜像 + 读写层。并且容器的定义并没有提及是否要运行容器。 接下来，我们将会讨论运行态容器。 运行态容器定义一个运行态容器（running container）被定义为一个可读写的统一文件系统加上隔离的进程空间和包含其中的进程。下面这张图片展示了一个运行中的容器。 正是文件系统隔离技术使得Docker成为了一个前途无量的技术。一个容器中的进程可能会对文件进行修改、删除、创建，这些改变都将作用于可读写层（read-write layer）。下面这张图展示了这个行为。 我们可以通过运行以下命令来验证我们上面所说的：1docker run ubuntu touch happiness.txt 即便是这个ubuntu容器不再运行，我们依旧能够在主机的文件系统上找到这个新文件。1find / -name happiness.txt 镜像层定义为了将零星的数据整合起来，我们提出了镜像层（image layer）这个概念。下面的这张图描述了一个镜像层，通过图片我们能够发现一个层并不仅仅包含文件系统的改变，它还能包含了其他重要信息。 元数据（metadata）就是关于这个层的额外信息，它不仅能够让Docker获取运行和构建时的信息，还包括父层的层次信息。需要注意，只读层和读写层都包含元数据。 除此之外，每一层都包括了一个指向父层的指针。如果一个层没有这个指针，说明它处于最底层。 Metadata Location:我发现在我自己的主机上，镜像层（image layer）的元数据被保存在名为”json”的文件中，比如说：1/var/lib/docker/graph/e809f156dc985.../json e809f156dc985…就是这层的id。 一个容器的元数据好像是被分成了很多文件，但或多或少能够在/var/lib/docker/containers/目录下找到，就是一个可读层的id。这个目录下的文件大多是运行时的数据，比如说网络，日志等等。 全局理解（Tying It All Together）现在，让我们结合上面提到的实现细节来理解Docker的命令。 docker create docker create 命令为指定的镜像（image）添加了一个可读层，构成了一个新的容器。注意，这个容器并没有运行。 docker start Docker start命令为容器文件系统创建了一个进程隔离空间。注意，每一个容器只能够有一个进程隔离空间。 docker run 看到这个命令，读者通常会有一个疑问：docker start 和 docker run命令有什么区别。 从图片可以看出，docker run 命令先是利用镜像创建了一个容器，然后运行这个容器。这个命令非常的方便，并且隐藏了两个命令的细节，但从另一方面来看，这容易让用户产生误解。 题外话：继续我们之前有关于Git的话题，我认为docker run命令类似于git pull命令。git pull命令就是git fetch 和 git merge两个命令的组合，同样的，docker run就是docker create和docker start两个命令的组合。1docker ps docker ps 命令会列出所有运行中的容器。这隐藏了非运行态容器的存在，如果想要找出这些容器，我们需要使用下面这个命令。1docker ps –a docker ps –a命令会列出所有的容器，不管是运行的，还是停止的。1docker images docker images命令会列出了所有顶层（top-level）镜像。实际上，在这里我们没有办法区分一个镜像和一个只读层，所以我们提出了top-level镜像。只有创建容器时使用的镜像或者是直接pull下来的镜像能被称为顶层（top-level）镜像，并且每一个顶层镜像下面都隐藏了多个镜像层。1docker images –a docker images –a命令列出了所有的镜像，也可以说是列出了所有的可读层。如果你想要查看某一个image-id下的所有层，可以使用docker history来查看。1docker stop &lt;container-id&gt; docker stop命令会向运行中的容器发送一个SIGTERM的信号，然后停止所有的进程。1docker kill &lt;container-id&gt; docker kill 命令向所有运行在容器中的进程发送了一个不友好的SIGKILL信号。1docker pause &lt;container-id&gt; docker stop和docker kill命令会发送UNIX的信号给运行中的进程，docker pause命令则不一样，它利用了cgroups的特性将运行中的进程空间暂停。具体的内部原理你可以在这里找到：https://www.kernel.org/doc/Documentation/cgroups/freezer-subsystem.txt，但是这种方式的不足之处在于发送一个SIGTSTP信号对于进程来说不够简单易懂，以至于不能够让所有进程暂停。1docker rm &lt;container-id&gt; docker rm命令会移除构成容器的可读写层。注意，这个命令只能对非运行态容器执行。1docker rmi &lt;image-id&gt; docker rmi 命令会移除构成镜像的一个只读层。你只能够使用docker rmi来移除最顶层（top level layer）（也可以说是镜像），你也可以使用-f参数来强制删除中间的只读层。1docker commit &lt;container-id&gt; docker commit命令将容器的可读写层转换为一个只读层，这样就把一个容器转换成了不可变的镜像。1docker build docker build命令非常有趣，它会反复的执行多个命令。 我们从上图可以看到，build命令根据Dockerfile文件中的FROM指令获取到镜像，然后重复地1）run（create和start）、2）修改、3）commit。在循环中的每一步都会生成一个新的层，因此许多新的层会被创建。1docker exec &lt;running-container-id&gt; docker exec 命令会在运行中的容器执行一个新进程。1docker inspect &lt;container-id&gt; or &lt;image-id&gt; docker inspect命令会提取出容器或者镜像最顶层的元数据。1docker save &lt;image-id&gt; docker save命令会创建一个镜像的压缩文件，这个文件能够在另外一个主机的Docker上使用。和export命令不同，这个命令为每一个层都保存了它们的元数据。这个命令只能对镜像生效。1docker export &lt;container-id&gt; docker export命令创建一个tar文件，并且移除了元数据和不必要的层，将多个层整合成了一个层，只保存了当前统一视角看到的内容（译者注：expoxt后的容器再import到Docker中，通过docker images –tree命令只能看到一个镜像；而save后的镜像则不同，它能够看到这个镜像的历史镜像）。1docker history &lt;image-id&gt; docker history命令递归地输出指定镜像的历史镜像。 参考http://dockone.io/article/783 http://sina.lt/gfmf]]></content>
      <categories>
        <category>容器化</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>容器化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引优化]]></title>
    <url>%2F2019%2F07%2F02%2FMySQL%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[MySQL索引的建立对于MySQL的高效运行是很重要的。对于少量的数据，没有合适的索引影响不是很大，但是，当随着数据量的增加，性能会急剧下降。如果对多列进行索引(组合索引)，列的顺序非常重要，MySQL仅能对索引最左边的前缀进行有效的查找。 下面介绍几种常见的MySQL索引类型。 索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。 索引类型主键索引 PRIMARY KEY它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引。 当然也可以用 ALTER 命令。记住：一个表只能有一个主键。 唯一索引 UNIQUE唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。可以在创建表的时候指定，也可以修改表结构，如：1ALTER TABLE table_name ADD UNIQUE (column) 普通索引 INDEX这是最基本的索引，它没有任何限制。可以在创建表的时候指定，也可以修改表结构，如：1ALTER TABLE table_name ADD INDEX index_name (column) 组合索引 INDEX组合索引，即一个索引包含多个列。可以在创建表的时候指定，也可以修改表结构，如：1ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3) 全文索引 FULLTEXT全文索引（也称全文检索）是目前搜索引擎使用的一种关键技术。它能够利用分词技术等多种算法智能分析出文本文字中关键字词的频率及重要性，然后按照一定的算法规则智能地筛选出我们想要的搜索结果。 可以在创建表的时候指定，也可以修改表结构，如：1ALTER TABLE table_name ADD FULLTEXT (column) 索引结构及原理mysql中普遍使用B+Tree做索引，但在实现上又根据聚簇索引和非聚簇索引而不同，本文暂不讨论这点。 b+树介绍下面这张b+树的图片在很多地方可以看到，之所以在这里也选取这张，是因为觉得这张图片可以很好的诠释索引的查找过程。如上图，是一颗b+树。浅蓝色的块我们称之为一个磁盘块，可以看到每个磁盘块包含几个数据项（深蓝色所示）和指针（黄色所示），如磁盘块1包含数据项17和35，包含指针P1、P2、P3，P1表示小于17的磁盘块，P2表示在17和35之间的磁盘块，P3表示大于35的磁盘块。 真实的数据存在于叶子节点，即3、5、9、10、13、15、28、29、36、60、75、79、90、99。非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35并不真实存在于数据表中。 查找过程在上图中，如果要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计，通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。 性质(1) 索引字段要尽量的小。 通过上面b+树的查找过程，或者通过真实的数据存在于叶子节点这个事实可知，IO次数取决于b+数的高度h。 假设当前数据表的数据量为N，每个磁盘块的数据项的数量是m，则树高h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小； 而m = 磁盘块的大小/数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的；如果数据项占的空间越小，数据项的数量m越多，树的高度h越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。 (2) 索引的最左匹配特性。 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 建表、索引语句示例12345678910111213141516171819202122232425262728建表：create table student( stu_id int unsigned not null auto_increment, name varchar(32) not null default '', phone char(11) not null default '', stu_code varchar(32) not null default '', stu_desc text, primary key ('stu_id'), //主键索引 unique index 'stu_code' ('stu_code'), //唯一索引 index 'name_phone' ('name','phone'), //普通索引，复合索引 fulltext index 'stu_desc' ('stu_desc'), //全文索引) engine=myisam charset=utf8;说明：MySQL5.6版本后的InnoDB存储引擎开始支持全文索引，5.7版本后通过使用ngram插件开始支持中文。更新：alter table student add primary key ('stu_id'), //主键索引 add unique index 'stu_code' ('stu_code'), //唯一索引 add index 'name_phone' ('name','phone'), //普通索引，复合索引 add fulltext index 'stu_desc' ('stu_desc'); //全文索引删除：alter table sutdent drop primary key, drop index 'stu_code', drop index 'name_phone', drop index 'stu_desc'; 索引的使用原则尽量选择区分度高的列作为索引索引列不能参与计算，保持列“干净”保证索引包含的字段独立在查询语句中，不能是在表达式中。 比如：Flistid+1&gt;’2000000608201108010831508721’。原因很简单，假如索引列参与计算的话，那每次检索时，都会先将索引计算一次，再做比较，显然成本太大。 最左前缀匹配原则对于多列索引，总是从索引的最前面字段开始，接着往后，中间不能跳过。比如创建了多列索引(a,b,c)，会先匹配a字段，再匹配b字段，再匹配c字段的，中间不能跳过。mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配。 语句 索引是否发挥作用 where a=3 是，只使用了a where a=3 and b=5 是，使用了a,b where a=3 and b=5 and c=4 是，使用了a,b,c where b=3 or c=4 否 where a=3 and c=4 是，仅使用了a where a=3 and b&gt;10 and c=7 是，使用了a,b where a=3 and b like ‘%xx%’ and c=7 使用了a,b or的两边都有存在可用的索引，该语句才能用索引。 一般，在创建多列索引时，where子句中使用最频繁的一列放在最左边。 不要滥用索引，多余的索引会降低读写性能=和in可以乱序比如a = 1 and b = 2 and c = 3，建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。 即使满足了上述原则，mysql还是可能会弃用索引，因为有些查询即使使用索引，也会出现大量的随机io，相对于从数据记录中的顺序io开销更大。 mysql 中能够使用索引的典型应用测试库下载地址：https://downloads.mysql.com/d… 这里，先普及下explain之后的type和extra内容，具体可看以下文章： https://mengkang.net/1124.html https://www.cnblogs.com/kerrycode/p/9909093.html 匹配全值（match the full value）对索引中所有列都指定具体值，即是对索引中的所有列都有等值匹配的条件。例如，租赁表 rental 中通过指定出租日期 rental_date + 库存编号 inventory_id + 客户编号 customer_id 的组合条件进行查询，从执行计划的 key he extra 两字段的值看到优化器选择了复合索引 idx_rental_date: 关于explain结果值及其含义可以参考我的另一篇博客MySql数据库中的索引123456789101112131415MySQL [sakila]&gt; explain select * from rental where rental_date=&apos;2005-05-25 17:22:10&apos; and inventory_id=373 and customer_id=343 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: rental partitions: NULL type: constpossible_keys: rental_date,idx_fk_inventory_id,idx_fk_customer_id key: rental_date key_len: 10 ref: const,const,const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) explain 输出结果中字段 type 的值为 const，表示是常量；字段 key 的值为 rental_date, 表示优化器选择索引 rental_date 进行扫描。 匹配值的范围查询（match a range of values）对索引的值能够进行范围查找。 例如，检索租赁表 rental 中客户编号 customer_id 在指定范围内的记录：123456789101112131415MySQL [sakila]&gt; explain select * from rental where customer_id &gt;= 373 and customer_id &lt; 400 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: rental partitions: NULL type: rangepossible_keys: idx_fk_customer_id key: idx_fk_customer_id key_len: 2 ref: NULL rows: 718 filtered: 100.00 Extra: Using index condition 1 row in set, 1 warning (0.05 sec) 类型 type 为 range 说明优化器选择范围查询，索引 key 为 idx_fk_customer_id 说明优化器选择索引 idx_fk_customer_id 来加速访问，注意到这个列子中 extra 列为 using index codition ,表示 mysql 使用了 ICP（using index condition） 来进一步优化查询。 匹配最左前缀（match a leftmost prefix）仅仅使用索引中的最左边列进行查询，比如在 col1 + col2 + col3 字段上的联合索引能够被包含 col1、(col1 + col2)、（col1 + col2 + col3）的等值查询利用到，可是不能够被 col2、（col2、col3）的等值查询利用到。 最左匹配原则可以算是 MySQL 中 B-Tree 索引使用的首要原则。 仅仅对索引进行查询（index only query）当查询的列都在索引的字段中时，查询的效率更高，所以应该尽量避免使用 select *，需要哪些字段，就只查哪些字段。 匹配列前缀（match a column prefix）仅仅使用索引中的第一列，并且只包含索引第一列的开头一部分进行查找。 例如，现在需要查询出标题 title 是以 AFRICAN 开头的电影信息，从执行计划能够清楚看到，idx_title_desc_part 索引被利用上了：1234567891011121314151617181920MySQL [sakila]&gt; create index idx_title_desc_part on film_text(title (10), description(20));Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0MySQL [sakila]&gt; explain select title from film_text where title like &apos;AFRICAN%&apos;\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: film_text partitions: NULL type: rangepossible_keys: idx_title_desc_part,idx_title_description key: idx_title_desc_part key_len: 32 ref: NULL rows: 1 filtered: 100.00 Extra: Using where 1 row in set, 1 warning (0.00 sec)extra 值为 using where 表示优化器需要通过索引回表查询数据。 能够实现索引匹配部分精确而其他部分进行范围匹配（match one part exactly and match a range on another part） 例如，需要查询出租日期 rental_date 为指定日期且客户编号 customer_id 为指定范围的库存：123456789101112131415MySQL [sakila]&gt; MySQL [sakila]&gt; explain select inventory_id from rental where rental_date=&apos;2006-02-14 15:16:03&apos; and customer_id &gt;= 300 and customer_id &lt;=400\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: rental partitions: NULL type: refpossible_keys: rental_date,idx_fk_customer_id key: rental_date key_len: 5 ref: const rows: 182 filtered: 16.85 Extra: Using where; Using index 1 row in set, 1 warning (0.00 sec) 如果列名是索引，那么使用 column_name is null 就会使用索引。 例如，查询支付表 payment 的租赁编号 rental_id 字段为空的记录就用到了索引：123456789101112131415MySQL [sakila]&gt; explain select * from payment where rental_id is null \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: payment partitions: NULL type: refpossible_keys: fk_payment_rental key: fk_payment_rental key_len: 5 ref: const rows: 5 filtered: 100.00 Extra: Using index condition 1 row in set, 1 warning (0.00 sec) 存在索引但不能使用索引的典型场景有些时候虽然有索引，但是并不被优化器选择使用，下面举例几个不能使用索引的场景。 以%开头的 like 查询不能利用 B-Tree 索引，执行计划中 key 的值为 null 表示没有使用索引123456789101112131415MySQL [sakila]&gt; explain select * from actor where last_name like &quot;%NI%&quot;\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: actor partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 200 filtered: 11.11 Extra: Using where 1 row in set, 1 warning (0.00 sec) 因为 B-Tree 索引的结构，所以以%开头的插叙很自然就没法利用索引了。一般推荐使用全文索引（Fulltext）来解决类似的全文检索的问题。或者考虑利用 innodb 的表都是聚簇表的特点，采取一种轻量级别的解决方式：一般情况下，索引都会比表小，扫描索引要比扫描表更快，而Innodb 表上二级索引 idx_last_name 实际上存储字段 last_name 还有主键 actot_id,那么理想的访问应该是首先扫描二级索引 idx_last_name 获得满足条件的last_name like ‘%NI%’ 的主键 actor_id 列表，之后根据主键回表去检索记录，这样访问避开了全表扫描演员表 actor 产生的大量 IO 请求。123456789101112131415161718192021222324252627MySQL [sakila]&gt; explain select * from (select actor_id from actor where last_name like &apos;%NI%&apos;) a , actor b where a.actor_id = b.actor_id \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: actor partitions: NULL type: indexpossible_keys: PRIMARY key: idx_actor_last_name key_len: 137 ref: NULL rows: 200 filtered: 11.11 Extra: Using where; Using index*************************** 2. row *************************** id: 1 select_type: SIMPLE table: b partitions: NULL type: eq_refpossible_keys: PRIMARY key: PRIMARY key_len: 2 ref: sakila.actor.actor_id rows: 1 filtered: 100.00 Extra: NULL 从执行计划中能够看出，extra 字段 using wehre；using index。理论上比全表扫描更快一下。 数据类型出现隐式转换的时候也不会使用索引当列的类型是字符串，那么一定记得在 where 条件中把字符常量值用引号引起来，否则即便这个列上有索引，mysql 也不会用到，因为 MySQL 默认把输入的常量值进行转换以后才进行检索。 例如，演员表 actor 中的姓氏字段 last_name 是字符型的，但是 sql 语句中的条件值 1 是一个数值型值，因此即便存在索引 idx_last_name, mysql 也不能正确的用上索引，而是继续进行全表扫描：12345678910111213141516171819202122232425262728293031MySQL [sakila]&gt; explain select * from actor where last_name = 1 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: actor partitions: NULL type: ALLpossible_keys: idx_actor_last_name key: NULL key_len: NULL ref: NULL rows: 200 filtered: 10.00 Extra: Using where 1 row in set, 3 warnings (0.00 sec)MySQL [sakila]&gt; explain select * from actor where last_name = &apos;1&apos;\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: actor partitions: NULL type: refpossible_keys: idx_actor_last_name key: idx_actor_last_name key_len: 137 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec) where条件不符合最左前缀原则时复合索引的情况下，假如查询条件不包含索引列最左边部分，即不满足最左原则 leftmost，是不会使用复合索引的。 使用！= 或 &lt;&gt; 操作符时尽量避免使用！= 或 &lt;&gt;操作符，否则数据库引擎会放弃使用索引而进行全表扫描。使用&gt;或&lt;会比较高效。 索引列参与计算应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。1select * from t_credit_detail where Flistid +1 &gt; '2000000608201108010831508722' 对字段进行null值判断应尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： 低效：select * from t_credit_detail where Flistid is null ; 可以在Flistid上设置默认值0，确保表中Flistid列没有null值，然后这样查询： 高效：select * from t_credit_detail where Flistid =0; 使用or来连接条件应尽量避免在where子句中使用or来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： 低效：select * from t_credit_detail where Flistid = ‘2000000608201108010831508721’ or Flistid = ‘10000200001’; 可以用下面这样的查询代替上面的 or 查询： 高效：select from t_credit_detail where Flistid = ‘2000000608201108010831508721’ union all select from t_credit_detail where Flistid = ‘10000200001’; 如果 MySQL 估计使用索引比全表扫描更慢，则不使用索引。 查看索引使用情况如果索引正在工作， Handler_read_key 的值将很高，这个值代表了一个行被索引值读的次数，很低的值表名增加索引得到的性能改善不高，因为索引并不经常使用。 Handler_read_rnd_next 的值高则意味着查询运行低效，并且应该建立索引补救。这个值的含义是在数据文件中读下一行的请求数。如果正在进行大量的表扫描，Handler_read_rnd_next 的值较高，则通常说明表索引不正确或写入的查询没有利用索引，具体如下。123456789101112MySQL [sakila]&gt; show status like &apos;Handler_read%&apos;;+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| Handler_read_first | 1 || Handler_read_key | 5 || Handler_read_last | 0 || Handler_read_next | 200 || Handler_read_prev | 0 || Handler_read_rnd | 0 || Handler_read_rnd_next | 0 |+-----------------------+-------+ 使用索引的小技巧字符串字段权衡区分度与长度的技巧截取不同长度，测试区分度1234567891011# 这里假设截取6个字符长度计算区别度，直到区别度达到0.1，就可以把这个字段的这个长度作为索引了mysql&gt; select count(distinct left([varchar]],6))/count(*) from table;#注意：设置前缀索引时指定的长度表示字节数，而对于非二进制类型(CHAR, VARCHAR, TEXT)字段而言的字段长度表示字符数，所# 以，在设置前缀索引前需要把计算好的字符数转化为字节数，常用字符集与字节的关系如下：# latin 单字节：1B# GBK 双字节：2B# UTF8 三字节：3B# UTF8mb4 四字节：4B # myisam 表的索引大小默认为 1000字节，innodb 表的索引大小默认为 767 字节，可以在配置文件中修改 innodb_large_prefix # 项的值增大 innodb 索引的大小，最大 3072 字节。 区别度能达到0.1，就可以。 左前缀不易区分的字段索引建立方法这样的字段，左边有大量重复字符，比如url字段汇总的http:// 倒过来存储并建立索引 新增伪hash字段 把字符串转化为整型 索引覆盖概念：如果查询的列恰好是索引的一部分，那么查询只需要在索引文件上进行，不需要回行到磁盘，这种查询，速度极快，江湖人称——索引覆盖 延迟关联在根据条件查询数据时，如果查询条件不能用的索引，可以先查出数据行的id，再根据id去取数据行。1234//普通查询 没有用到索引select * from post where content like &quot;%新闻%&quot;;//延迟关联优化后 内层查询走content索引，取出id,在用join查所有行select a.* from post as a inner join (select id from post where content like &quot;%新闻%&quot;) as b on a.id=b.id; 索引排序 排序的字段上加入索引，可以提高速度。任何在Order by语句的非索引项或者有计算表达式都将降低查询速度。 重复索引和冗余索引重复索引：在同一列或者相同顺序的几个列建立了多个索引，成为重复索引，没有任何意义，删掉冗余索引：两个或多个索引所覆盖的列有重叠，比如对于列m,n ，加索引index m(m),indexmn(m,n),称为冗余索引。 在Join表的时候使用相同类型的字段，并将其索引如果应用程序有很多JOIN 查询，你应该确认两个表中Join的字段是被建过索引的。这样，MySQL内部会启动为你优化Join的SQL语句的机制。 而且，这些被用来Join的字段，应该是相同的类型的。例如：如果你要把 DECIMAL 字段和一个 INT 字段Join在一起，MySQL就无法使用它们的索引。对于那些STRING类型，还需要有相同的字符集才行。（两个表的字符集有可能不一样） 索引碎片与维护在数据表长期的更改过程中，索引文件和数据文件都会产生空洞，形成碎片。修复表的过程十分耗费资源，可以用比较长的周期修复表。1234//清理方法alert table xxx engine innodb; //或optimize table xxx; innodb引擎的索引注意事项Innodb 表要尽量自己指定主键，如果有几个列都是唯一的，要选择最常作为访问条件的列作为主键，另外，Innodb 表的普通索引都会保存主键的键值，所以主键要尽可能选择较短的数据类型，可以有效的减少索引的磁盘占用，提高索引的缓存效果。 参考：https://machenxing.github.io/2018/12/19/Mysql%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/ https://segmentfault.com/a/1190000009717352 https://mp.weixin.qq.com/s/KDIpY22tfmsrOIAuZNw4ZQ https://cloud.tencent.com/developer/article/1004912]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云Redis开发规范]]></title>
    <url>%2F2019%2F07%2F01%2F%E9%98%BF%E9%87%8C%E4%BA%91Redis%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[键值设计key名设计(1)【建议】: 可读性和可管理性以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id1ugc:video:1 (2)【建议】：简洁性保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：1user:&#123;uid&#125;:friends:messages:&#123;mid&#125;简化为u:&#123;uid&#125;:fr:m:&#123;mid&#125;。 (3)【强制】：不要包含特殊字符反例：包含空格、换行、单双引号以及其他转义字符 value设计(1)【强制】：拒绝bigkey(防止网卡流量、慢查询)string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法 (2)【推荐】：选择适合的数据类型。例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡) 反例：123set user:1:name tomset user:1:age 19set user:1:favor football 正例:1hmset user:1 name tom age 19 favor football 3.【推荐】：控制key的生命周期，redis不是垃圾桶。建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。 命令使用1.【推荐】 O(N)命令关注N的数量 例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。 2.【推荐】：禁用命令 禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 3.【推荐】合理使用select redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4.【推荐】使用批量操作提高效率 原生命令：例如mget、mset。非原生命令：可以使用pipeline提高效率。但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同： 原生是原子操作，pipeline是非原子操作。 pipeline可以打包不同的命令，原生做不到 pipeline需要客户端和服务端同时支持。 5.【建议】Redis事务功能较弱，不建议过多使用 Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决) 6.【建议】Redis集群版本在使用Lua上有特殊要求： 所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，”-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array” 所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slot” 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。 客户端使用1.【推荐】避免多个应用使用一个Redis实例 正例：不相干的业务拆分，公共数据做服务化。 2.【推荐】使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式： 执行命令如下：123456789101112Jedis jedis = null;try &#123; jedis = jedisPool.getResource(); //具体的命令 jedis.executeCommand()&#125; catch (Exception e) &#123; logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123; //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close();&#125; 下面是JedisPool优化方法的文章: Jedis常见异常汇总 JedisPool资源池优化 3.【建议】 高并发下建议客户端添加熔断功能(例如netflix hystrix) 4.【推荐】 设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持） 5.【建议】 根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random:随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。 相关工具1.【推荐】：数据同步redis间数据同步可以使用：redis-port 2.【推荐】：big key搜索 redis大key搜索工具 3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用) facebook的redis-faina 阿里云Redis已经在内核层面解决热点key问题，欢迎使用。 附录：删除bigkey121. 下面操作可以使用pipeline加速。2. redis 4.0已经支持key的异步删除，欢迎使用。 1.Hash删除: hscan + hdel123456789101112131415161718192021public void delBigHash(String host, int port, String password, String bigHashKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams); List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult(); if (entryList != null &amp;&amp; !entryList.isEmpty()) &#123; for (Entry&lt;String, String&gt; entry : entryList) &#123; jedis.hdel(bigHashKey, entry.getKey()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigHashKey);&#125; 2.List删除: ltrim12345678910111213141516public void delBigList(String host, int port, String password, String bigListKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; long llen = jedis.llen(bigListKey); int counter = 0; int left = 100; while (counter &lt; llen) &#123; //每次从左侧截掉100个 jedis.ltrim(bigListKey, left, llen); counter += left; &#125; //最终删除key jedis.del(bigListKey);&#125; 3.Set删除: sscan + srem123456789101112131415161718192021public void delBigSet(String host, int port, String password, String bigSetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;String&gt; scanResult = jedis.sscan(bigSetKey, cursor, scanParams); List&lt;String&gt; memberList = scanResult.getResult(); if (memberList != null &amp;&amp; !memberList.isEmpty()) &#123; for (String member : memberList) &#123; jedis.srem(bigSetKey, member); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigSetKey);&#125; 4.SortedSet删除: zscan + zrem123456789101112131415161718192021public void delBigZset(String host, int port, String password, String bigZsetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Tuple&gt; scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); List&lt;Tuple&gt; tupleList = scanResult.getResult(); if (tupleList != null &amp;&amp; !tupleList.isEmpty()) &#123; for (Tuple tuple : tupleList) &#123; jedis.zrem(bigZsetKey, tuple.getElement()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigZsetKey);&#125; 参考 本文转载自：云栖社区]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM性能监控与故障处理工具]]></title>
    <url>%2F2019%2F05%2F21%2FJVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[引言在实际生产中，我们经常需要使用适当的监控和分析工具加快分析问题，定位解决问题。本文将介绍一些JVM中的性能监控与故障处理工具，其中大部分都是JDK自带的。采用的实验环境是Linux操作系统，JDK为openjdk 1.8.0_201。 jps：虚拟机进程状况工具jps（JVM Process Status Tool）除了名字像UNIX的ps命令之外，它的功能也和ps命令类似：可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier，LVMID）。虽然功能比较单一，但它是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到的LVMID来确定要监控的是哪一个虚拟机进程。对于本地虚拟机进程来说，LVMID与操作系统的进程ID（Process Identifier,PID）是一致的，使用Windows的任务管理器或者UNIX的ps命令也可以查询到虚拟机进程的LVMID，但如果同时启动了多个虚拟机进程，无法根据进程名称定位时，那就只能依赖jps命令显示主类的功能才能区分了。 jsp命令格式：jps [options] [hostid]。 我们在本机上执行一下：123456/ # jps -l1 /scheduler.jar1269 sun.tools.jps.Jps/ # jps -v1 jar -Djava.security.egd=file:/dev/./urandom1302 Jps -Dapplication.home=/usr/lib/jvm/java-1.8-openjdk -Xms8m 主要选项 选项 作用 -q 仅输出VM标识符，不包括class name,jar name,arguments in main method -m 输出虚拟机进程启动时传递给主类main()函数的参数 -l 输出完全的包名，应用主类名，jar的完全路径名 -v 输出JVM参数 -V 输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 jstat：虚拟机统计信息监视工具jstat（JVM Statistics Monitoring Tool）是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。 jstat命令格式为：jstat[ option vmid [interval[s|ms] [count]] ]。 对于命令格式中的VMID与LVMID需要特别说明一下：如果是本地虚拟机进程，VMID与LVMID是一致的，如果是远程虚拟机进程，那VMID的格式应当是：[protocol:][//]lvmid[@hostname[:port]/servername]。 参数interval和count代表查询间隔和次数，如果省略这两个参数，说明只查询一次。假设需要每500毫秒查询一次进程3999垃圾收集状况，一共查询10次，那命令应当是： 12345678/ # jstat -gc 1 500 10 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 4096.0 4096.0 0.0 3328.0 253952.0 133671.7 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133706.1 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133706.1 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133740.6 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.3234096.0 4096.0 0.0 3328.0 253952.0 133740.6 102912.0 74309.5 77952.0 76822.8 8576.0 8301.2 4885 99.323 5 2.000 101.323... 主要选项 选项 作用 -class 监视类装载、卸载数量、总空间以及类装载所耗费的时间。 -gc 监视Java堆状况，包括Eden区、两个survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息。 -gccapacity 监视内容与-gc 基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间。 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比。 -gccause 与-gcuti功能一样，但是会额外输出导致上一次GC产生的原因。 -gcnew 监视新生代GC状况。 -gcnewcapacity 监视内容与-genew基本相同，输出主要关注使用到的最大、最小空间。 -gcold 监视老年代GC状况。 -gcoldcapacity 监视内容与gcold 基本相同，输出主要关注使用到的最大、最小空间。 -gcpermcapacity 输出永久代使用到的最大、最小空间。 -compiler 输出JIT编译器编译过的方法、耗时等信息。 -printcompilation 输出已经被JIT编译的方法。 各命令显示内容含义 jstat –class \&lt;pid>：监视类装载、卸载数量、总空间以及类装载所耗费的时间。123/ # jstat -class 1Loaded Bytes Unloaded Bytes Time 12551 24437.3 115 167.4 36.37 显示列名 具体描述 Loaded 装载的类的数量 Bytes 装载类所占用的字节数 Unloaded 卸载类的数量 Bytes 卸载类的字节数 Time 装载和卸载类所花费的时间 jstat -gc \&lt;pid>：监视Java堆状况，包括Eden区、两个survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息。123/ # jstat -gc 1 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 4096.0 4096.0 3344.0 0.0 253952.0 177177.3 102912.0 74365.5 77952.0 76822.8 8576.0 8301.2 4894 99.537 5 2.000 101.538 显示列名 具体描述 S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) S0U 年轻代中第一个survivor（幸存区）目前已使用空间 (字节) S1U 年轻代中第二个survivor（幸存区）目前已使用空间 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) EU 年轻代中Eden（伊甸园）目前已使用空间 (字节) OC Old代的容量 (字节) OU Old代目前已使用空间 (字节) PC Perm(持久代)的容量 (字节) PU Perm(持久代)目前已使用空间 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jstat -gccapacity \&lt;pid>：监视内容与-gc 基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间。123/ # jstat -gccapacity 1 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 16384.0 262144.0 262144.0 4096.0 4096.0 253952.0 32768.0 524288.0 102912.0 102912.0 0.0 1118208.0 77952.0 0.0 1048576.0 8576.0 4899 5 显示列名 具体描述 NGCMN 年轻代(young)中初始化(最小)的大小(字节) NGCMX 年轻代(young)的最大容量 (字节) NGC 年轻代(young)中当前的容量 (字节) S0C 年轻代中第一个survivor（幸存区）的容量 (字节) S1C 年轻代中第二个survivor（幸存区）的容量 (字节) EC 年轻代中Eden（伊甸园）的容量 (字节) OGCMN old代中初始化(最小)的大小 (字节) OGCMX old代的最大容量(字节) OGC old代当前新生成的容量 (字节) OC Old代的容量 (字节) PGCMN perm代中初始化(最小)的大小 (字节) PGCMX perm代的最大容量 (字节) PGC perm代当前新生成的容量 (字节) PC Perm(持久代)的容量 (字节) YGC 从应用程序启动到采样时年轻代中gc次数 FGC 从应用程序启动到采样时old代(全gc)gc次数 jstat -gcutil \&lt;pid>：监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比。123/ # jstat -gcutil 1 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 85.94 38.56 72.31 98.55 96.80 4899 99.659 5 2.000 101.660 显示列名 具体描述 S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 E 年轻代中Eden（伊甸园）已使用的占当前容量百分比 O old代已使用的占当前容量百分比 P perm代已使用的占当前容量百分比 YGC 从应用程序启动到采样时年轻代中gc次数 YGCT 从应用程序启动到采样时年轻代中gc所用时间(s) FGC 从应用程序启动到采样时old代(全gc)gc次数 FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s) GCT 从应用程序启动到采样时gc用的总时间(s) jstat -compiler ：输出JIT编译器编译过的方法、耗时等信息。123/ # jstat -compiler 1Compiled Failed Invalid Time FailedType FailedMethod 16516 6 0 371.01 1 com/mysql/jdbc/AbandonedConnectionCleanupThread run 显示列名 具体描述 Compiled 编译任务执行数量 Failed 编译任务执行失败数量 Invalid 编译任务执行失效数量 Time 编译任务消耗时间 FailedType 最后一次编译失败的编译类型 FailedMethod 最后一个编译失败任务所在的类及方法 jinfo：Java配置信息工具info（Configuration Info for Java）的作用是实时地查看和调整虚拟机各项参数。使用jps命令的-v参数可以查看虚拟机启动时显式指定的参数列表，但如果想知道未被显式指定的参数的系统默认值，除了去找资料外，就只能使用jinfo的-flag选项进行查询了（如果只限于JDK 1.6或以上版本的话，使用java-XX：+PrintFlagsFinal查看参数默认值也是一个很好的选择），jinfo还可以使用-sysprops选项把虚拟机进程的System.getProperties()的内容打印出来。这个命令在JDK 1.5时期已经随着Linux版的JDK发布，当时只提供了信息查询的功能，JDK 1.6之后，jinfo在Windows和Linux平台都有提供，并且加入了运行期修改参数的能力，可以使用-flag [+|-] name或者-flag name=value修改一部分运行期可写的虚拟机参数值。JDK 1.6中，jinfo对于Windows平台功能仍然有较大限制，只提供了最基本的-flag选项。 jinfo命令格式：jinfo [option] [pid]。 jmap：Java内存映像工具jmap（Memory Map for Java）命令用于生成堆转储快照（一般称为heapdump或dump文件）。如果不使用jmap命令，要想获取Java堆转储快照，还有一些比较“暴力”的手段：譬如-XX:+HeapDumpOnOutOfMemoryError参数，可以让虚拟机在OOM异常出现之后自动生成dump文件，通过-XX:+HeapDumpOnCtrlBreak参数则可以使用[Ctrl]+[Break]键让虚拟机生成dump文件，又或者在Linux系统下通过kill -3命令发送进程退出信号“吓唬”一下虚拟机，也能拿到dump文件。 jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。 和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的-dump选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。 jmap命令格式：jmap [option] [vmid]。 比如我们使用jmap生成一个正在运行的Java应用的dump快照文件，生成的文件可以用Eclipse MAT插件进行分析 jmap -dump:format=b,file=test.hprof 1 主要选项 选项 作用 -dump 生成Java堆转储快照。格式为：-dump:[live,]format=b,file=，其中live子参数说明是否只dump出存活的对象。 -finalizerinfo 显示在F-Queue中等待Finalizer线程执行finalize方法的对象。只在Linux/Solaris平台下有效。 -heap 显示Java堆详细信息，如使用哪种回收器、参数配置、分代状况等。只在Linux/Solaris平台下有效。 -histo 显示堆中对象统计信息，包括类、实例数量和合计容量。 -permstat 以ClassLoader为统计口径显示永久代内存状态。只在Linux/Solaris平台下有效 。 -F 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生成dump快照。只在Linux/Solaris平台下有效。 jstack：Java堆栈跟踪工具jstack（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。 jstack命令格式：jstack [option] [vmid]1234567891011121314151617/ # jstack -l 1"DiscoveryClient-2" #87 daemon prio=5 os_prio=0 tid=0x00007f5fb4004000 nid=0x67 waiting on condition [0x00007f5fb9cdf000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x00000005d0d515b8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093) at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809) at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Locked ownable synchronizers: - None ... 主要选项 选项 作用 -F 当正常输出的请求不被响应时，强制输出线程堆栈。 -l 除堆栈外，显示关于锁的附加信息。 -m 如果调用到本地方法的话，可以显示C/C++的堆栈。 参考资料： http://chengfeng96.com/blog/2018/04/11/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E4%B8%8E%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/ 《深入理解Java虚拟机》-周志明著]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Redis和令牌桶算法实现的集群接口限流器]]></title>
    <url>%2F2019%2F05%2F20%2F%E5%9F%BA%E4%BA%8ERedis%E5%92%8C%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E7%9A%84%E9%9B%86%E7%BE%A4%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81%E5%99%A8%2F</url>
    <content type="text"><![CDATA[任何系统的性能都有一个上限，当并发量超过这个上限之后，可1能会对系统造成毁灭性地打击。因此在任何时刻我们都必须保证系统的并发请求数量不能超过某个阈值，限流就是为了完成这一目的。本限流器是基于Redis记录流量数据，实现对接口的精准限流，保证系统的稳定运行。 1 令牌桶算法该限流器采用流行的令牌桶算法，现简单讲解令牌桶算法的原理 1.1 简介令牌桶算法最初来源于计算机网络。在网络传输数据时，为了防止网络拥塞，需限制流出网络的流量，使流量以比较均匀的速度向外发送。令牌桶算法就实现了这个功能，可控制发送到网络上数据的数目，并允许突发数据的发送。 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。 大小固定的令牌桶可自行以恒定的速率源源不断地产生令牌。如果令牌不被消耗，或者被消耗的速度小于产生的速度，令牌就会不断地增多，直到把桶填满。后面再产生的令牌就会从桶中溢出。最后桶中可以保存的最大令牌数永远不会超过桶的大小。 传送到令牌桶的数据包需要消耗令牌。不同大小的数据包，消耗的令牌数量不一样。令牌桶这种控制机制基于令牌桶中是否存在令牌来指示什么时候可以发送流量。令牌桶中的每一个令牌都代表一个字节。如果令牌桶中存在令牌，则允许发送流量；而如果令牌桶中不存在令牌，则不允许发送流量。因此，如果突发门限被合理地配置并且令牌桶中有足够的令牌，那么流量就可以以峰值速率发送。 1.2 算法过程算法描述： 假如用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中（每秒会有r个令牌放入桶中）； 假设桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃； 当一个n个字节的数据包到达时，就从令牌桶中删除n个令牌（不同大小的数据包，消耗的令牌数量不一样），并且数据包被发送到网络； 如果令牌桶中少于n个令牌，那么不会删除令牌，并且认为这个数据包在流量限制之外（n个字节，需要n个令牌。该数据包将被缓存或丢弃）； 算法允许最长b个字节的突发，但从长期运行结果看，数据包的速率被限制成常量r。对于在流量限制外的数据包可以以不同的方式处理：（1）它们可以被丢弃；（2）它们可以排放在队列中以便当令牌桶中累积了足够多的令牌时再传输；（3）它们可以继续发送，但需要做特殊标记，网络过载的时候将这些特殊标记的包丢弃。 2 实现原理本限流器主要是基于令牌桶思想，并将令牌数存储到Redis中，实现在集群模式下对接口的精准限流，实现思想如下： 对于每个限流接口，记录最大存储令牌数maxPermits， 当前存储令牌数storedPermits， 添加令牌时间间隔intervalMillis， 下次请求可以获取令牌的起始时间nextFreeTicketMillis，这些信息都记录在Redis中 响应本次请求之后，动态计算下一次可以服务的时间，如果下一次请求在这个时间之前则需要进行等待。 nextFreeTicketMicros 记录下一次可以响应的时间。例如，如果我们设置QPS为1，本次请求处理完之后，那么下一次最早的能够响应请求的时间一秒钟之后。 限流器支持处理突发流量请求，突发请求允许个数就是最大存储令牌数maxPermits。例如，我们设置QPS为1，在十秒钟之内没有请求，那么令牌桶中会有10个（假设设置的maxPermits为10）空闲令牌，如果下一次请求是 10个令牌，则可以一次性获取10个令牌，因为令牌桶中已经有10个空闲的令牌。 storedPermits 就是用来表示当前令牌桶中的空闲令牌数。 对于令牌的产生有两种方式，一种是通过后台定时任务来不断产生令牌，一种是延迟生成，在每次获取令牌之前先计算在nextFreeTicketMillis到目前这个时间段内应该产生多少令牌，并更新令牌桶。本限流器采用的是后者。 3 具体实现3.1 令牌桶1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * Redis令牌桶 */@Datapublic class RedisPermits implements Serializable &#123; private static final long serialVersionUID = 1L; /** * maxPermits 最大存储令牌数 */ private Long maxPermits; /** * storedPermits 当前存储令牌数 */ private Long storedPermits; /** * intervalMillis 添加令牌时间间隔 */ private Long intervalMillis; /** * nextFreeTicketMillis 下次请求可以获取令牌的起始时间，默认当前系统时间 */ private Long nextFreeTicketMillis; /** * @param permitsPerSecond 每秒放入的令牌数 * @param maxBurstSeconds maxPermits由此字段计算，最大存储maxBurstSeconds秒生成的令牌 */ public RedisPermits(Double permitsPerSecond, Integer maxBurstSeconds) &#123; if (null == maxBurstSeconds) &#123; maxBurstSeconds = 60; &#125; this.maxPermits = (long) (permitsPerSecond * maxBurstSeconds); this.storedPermits = permitsPerSecond.longValue(); this.intervalMillis = (long) (TimeUnit.SECONDS.toMillis(1) / permitsPerSecond); this.nextFreeTicketMillis = System.currentTimeMillis(); &#125; /** * redis的过期时长 * @return */ public Long expires() &#123; long now = System.currentTimeMillis(); return 2 * TimeUnit.MINUTES.toSeconds(1) + TimeUnit.MILLISECONDS.toSeconds(Math.max(nextFreeTicketMillis, now) - now); &#125; public Map&lt;String, String&gt; toMap() &#123; Map&lt;String, String&gt; resultMap = new HashMap&lt;&gt;(); resultMap.put("maxPermits", maxPermits.toString()); resultMap.put("storedPermits", storedPermits.toString()); resultMap.put("intervalMillis", intervalMillis.toString()); resultMap.put("nextFreeTicketMillis", nextFreeTicketMillis.toString()); return resultMap; &#125; 该类主要存储了令牌桶核心的四个参数 3.2 限流器主要方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139@Slf4j@Datapublic class RateLimiter &#123; /** * 在超时时间内尝试获取&#123;tokenCount&#125;个令牌 * @param tokenCount * @param timeout * @param timeUnit * @return * @throws InterruptedException */ public boolean tryAcquire(Long tokenCount, Long timeout, TimeUnit timeUnit) throws InterruptedException&#123; if(checkTokens(tokenCount)) &#123; Long timeoutMillis = Math.max(timeUnit.toMillis(timeout), 0); Long millisToWait = tryAndGetWaitTime(tokenCount, timeoutMillis); if(millisToWait &lt;= timeoutMillis) &#123; log.info("tryAcquire for &#123;&#125;ms &#123;&#125;", millisToWait, Thread.currentThread().getName()); Thread.sleep(millisToWait); return true; &#125; &#125; return false; &#125; /** * 等待直到获取指定数量的令牌 * @param tokenCount * @return * @throws InterruptedException */ public Long acquire(Long tokenCount) throws InterruptedException &#123; long milliToWait = this.reserve(tokenCount); log.info("acquire for &#123;&#125;ms &#123;&#125;", milliToWait, Thread.currentThread().getName()); Thread.sleep(milliToWait); return milliToWait; &#125; /** * 获取令牌n个需要等待的时间 * @param tokenCount * @return */ private long reserve(Long tokenCount) &#123; if (checkTokens(tokenCount)) &#123; return reserveAndGetWaitTime(tokenCount); &#125; else &#123; return -1; &#125; &#125; /** * 预定@&#123;tokenCount&#125;个令牌并返回所需要等待的时间 * @param tokenCount * @return */ private Long reserveAndGetWaitTime(Long tokenCount)&#123; putDefaultPermits(); String script = "redis.replicate_commands() " + "local redisKey = KEYS[1] " + "local timeStrArray = redis.call('time') " + "local seconds = tonumber(timeStrArray[1]) " + "local microseconds = tonumber(timeStrArray[2]) " + "local nowMilliseconds = seconds * 1000 + math.modf(microseconds/1000) " + "local redisPermitsValues = redis.call('hmget', redisKey, 'nextFreeTicketMillis', 'maxPermits', 'storedPermits', 'intervalMillis') " + "local nextFreeTicketMillis = tonumber(redisPermitsValues[1]) " + "local maxPermits = tonumber(redisPermitsValues[2]) " + "local storedPermits = tonumber(redisPermitsValues[3]) " + "local intervalMillis = tonumber(redisPermitsValues[4]) " + "if(nowMilliseconds &gt; nextFreeTicketMillis) " + "then " + "storedPermits = math.min(maxPermits, storedPermits + math.modf((nowMilliseconds - nextFreeTicketMillis) / intervalMillis)) " + "nextFreeTicketMillis = nowMilliseconds " + "end " + "local tokenCount = tonumber(ARGV[1]) " + "local storedPermitsToSpend = math.min(tokenCount, storedPermits) " + "local freshPermits = tokenCount - storedPermitsToSpend " + "local waitMillis = freshPermits * intervalMillis " + "nextFreeTicketMillis = nextFreeTicketMillis + waitMillis " + "storedPermits = storedPermits - storedPermitsToSpend " + "redis.call('hmset', redisKey, 'nextFreeTicketMillis', nextFreeTicketMillis, 'storedPermits', storedPermits) " + "redis.call('expire', redisKey, 120) " + "return nextFreeTicketMillis - nowMilliseconds"; List&lt;String&gt; keys = Collections.singletonList(key); List&lt;String&gt; args = Collections.singletonList(tokenCount.toString()); Object obj = redisUtil.eval(script, keys, args); Long result = null; if(obj != null) &#123; result = (Long) obj; &#125; return result; &#125; /** * 判断&#123;timeout&#125;时间内能否获取&#123;tokenCount&#125;令牌，如果能获取到则预定令牌 * @param tokenCount * @return 需要等待时长 */ private Long tryAndGetWaitTime(Long tokenCount, Long timeoutMillis) &#123; putDefaultPermits(); String script = "redis.replicate_commands() " + "local redisKey = KEYS[1] " + "local timeStrArray = redis.call('time') " + "local seconds = tonumber(timeStrArray[1]) " + "local microseconds = tonumber(timeStrArray[2]) " + "local nowMilliseconds = seconds * 1000 + math.modf(microseconds/1000) " + "local redisPermitsValues = redis.call('hmget', redisKey, 'nextFreeTicketMillis', 'maxPermits', 'storedPermits', 'intervalMillis') " + "local nextFreeTicketMillis = tonumber(redisPermitsValues[1]) " + "local maxPermits = tonumber(redisPermitsValues[2]) " + "local storedPermits = tonumber(redisPermitsValues[3]) " + "local intervalMillis = tonumber(redisPermitsValues[4]) " + "if(nowMilliseconds &gt; nextFreeTicketMillis) " + "then " + "storedPermits = math.min(maxPermits, storedPermits + math.modf((nowMilliseconds - nextFreeTicketMillis) / intervalMillis)) " + "nextFreeTicketMillis = nowMilliseconds " + "end " + "local tokenCount = tonumber(ARGV[1]) " + "local timeoutMillis = tonumber(ARGV[2]) " + "local storedPermitsToSpend = math.min(tokenCount, storedPermits) " + "local freshPermits = tokenCount - storedPermitsToSpend " + "local waitMillis = freshPermits * intervalMillis " + "local actualWaitMillis = nextFreeTicketMillis + waitMillis - nowMilliseconds " + "if(actualWaitMillis &lt;= timeoutMillis) " + "then " + "nextFreeTicketMillis = nextFreeTicketMillis + waitMillis " + "storedPermits = storedPermits - storedPermitsToSpend " + "redis.call('hmset', redisKey, 'nextFreeTicketMillis', nextFreeTicketMillis, 'storedPermits', storedPermits) " + "redis.call('expire', redisKey, 120) " + "end " + "return actualWaitMillis"; List&lt;String&gt; keys = Collections.singletonList(key); List&lt;String&gt; args = Arrays.asList(tokenCount.toString(), timeoutMillis.toString()); Object obj = redisUtil.eval(script, keys, args); Long result = null; if(obj != null) &#123; result = (Long) obj; &#125; return result; &#125;&#125; 可以看到，限流器的主要方法是acquire和tryAcquire，前者是进行线程阻塞以等待令牌桶中达到所需令牌，后者是设定超时时间，并判断在超时时间内能否获取所需令牌，可以的话再进行线程阻塞等待令牌。获取由于存储在Redis中的令牌桶信息在集群环境下会有线程不同步问题，虽然采用Redis分布锁可以解决该问题，但是会造成线程阻塞，降低并发效率。而Redis运行lua脚本是原子性操作，因此本文采用lua脚本执行对令牌桶的计算和更新操作。可以看到核心方法reserveAndGetWaitTime和tryAndGetWaitTime方法都使用了lua脚本，下面简单讲解一下这两个方法的实现逻辑。 reserveAndGetWaitTime 更新令牌桶，这一步操作就是上文讲到的延迟更新令牌 计算所需令牌数与令牌桶中令牌数的插值，确定补全所需令牌数需要等待的时间 取令牌并将令牌桶数据更新到Redis tryAndGetWaitTime 同样是先更新令牌桶 计算所需令牌数与令牌桶中令牌数的插值，确定补全所需令牌数需要等待的时间 判断等待的时间是否在超时时间内，如果是的话再取令牌将令牌桶数据更新到Redis]]></content>
      <categories>
        <category>常用组件</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>限流</tag>
        <tag>令牌桶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓存常用问题及解决方案]]></title>
    <url>%2F2019%2F01%2F20%2F%E7%BC%93%E5%AD%98%E5%B8%B8%E7%94%A8%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言为了应对互联网系统的海量访问，提高系统的qps，目前绝大部分系统都采用了缓存机制，避免数据库有限的IO成为系统瓶颈，极大的提升了用户体验和系统稳定性。虽然使用缓存给系统带来了质的提升，但同时也带来了一些需要注意的问题。本文将讲述缓存常见的问题及解决方案。 缓存穿透缓存穿透是指访问一个缓存中没有的数据，但是这个数据数据库中也不存在。普通思路下我们没有从数据库中拿到数据是不会触发加缓存操作的。这时如果是有人恶意攻击，大量的访问就会透过缓存直接打到数据库，对后端服务和数据库做成巨大的压力甚至宕机。 解决方案针对缓存穿透，业界主要有以下两种解决方案： 1、空值缓存这是一种比较简单的解决方案，在第一次查询的时候，如果缓存未命中，并且从数据库的也查不到数据，就将该Key和null值缓存起来，并且设置一个较短的过期时间，例如5分钟。这样就可以应对短时间内利用同一Key值进行的攻击。 2、Bloom Filter（布隆过滤器）Bloom Filter是空间效率高的概率型数据结构，用来检查一个元素是否在一个集合中。虽然其他数据结构例如Set和HashMap同样能够检查元素的存在性，但是Bloom Filter极高的空间利用率是其他结构不可比拟的，因此也特别适用于海量数据的建索。它的核心就是一个Bit Array和k个独立的哈希函数。 添加元素的时候，通过k个哈希函数找到对应于Bit Array上的k个位置，并将这k个位置置1； 查询的时候，将要查询的元素进行k个哈希函数计算，找到Bit Array上的k个位置，如果这个k个位置都为1，说明该元素可能存在，否则一定不存在。注意，这里只能说明可能存在，而是存在一定的误判率。这是由于这k个为值1的位置，有可能是其他几个元素计算后的值。误判率是Bloom Filter的一个缺陷。 这里再回到缓存穿透的解决上，我们可以将Bloom Filter放到缓存之前。在查询元素的时候，先通过Bloom filter判断元素是否存在，进而再决定是否请求缓存。 上述两种解决方案都有各自的使用场景：空值缓存可以很好的应对同一Key值的攻击，并且代码维护简单，但是如果攻击的Key值每次都不同，那么缓存中就会出现造成大量无用的空值缓存，并且由于每次攻击的Key不同，还是会穿透到数据库，起不到保护数据库的作用。而Bloom Filter则可以很好应对多个Key值的攻击。 缓存雪崩由于缓存层承载着大量请求，有效的保护了存储层，但是如果缓存层由于某些原因整体不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 缓存雪崩的英文原意是stampeding herd（奔逃的野牛），指的是缓存层宕掉后，流量会像奔逃的野牛一样，打向后端存储。造成缓存雪崩的原因通常有两个： 缓存集中在一段时间内失效，发生大量的缓存穿透，所有的查询都落在数据库上，造成了缓存雪崩。 缓存服务发生故障挂了而不响应或者由于网络故障等原因连接超时了，造成所有的查询都落到数据库上 解决方案1、加锁排队缓存在集中失效后，将对应Key的缓存更新任务放入队列，并对Key值加分布式锁。这时候由一个线程负责监听更新队列，并逐一取出任务进行缓存更新。等待缓存更新后，解锁Key值。大量访问请求需要排队等待Key值解锁，获取更新后的缓存。这种方式可以避免大量请求到数据库，但是缺点也很明显。由于等待锁期间会有大量线程阻塞,因此也极大降低了系统的QPS。 2、交错失效时间这种方法比较简单粗暴，既然在同一时间失效会造成请求过多雪崩，那我们错开不同的失效时间，让缓存失效均匀点，即可从一定程度上避免这种问题。在缓存进行失效时间设置的时候，从某个适当的值域中随机一个时间作为失效时间即可。 3、二级缓存做二级缓存策略，L1为一级缓存，为本地缓存，这里推荐用Caffeine实现；L2为二级缓存，为缓存服务缓存。L1缓存失效时间设置为短期，L2设置失效时间较长于L1。这时候当L1失效时，可以访问L2。这样，通过二级缓存这样就可以避免一部分缓存雪崩的情况。但是，二级缓存的维护难度较大，需要设计好更新策略，提高数据一致性。 4、缓存服务高可用将缓存服务设计成高可用的，保证在个别节点、个别机器、甚至是机房宕掉的情况下，依然可以提供服务。目前Redis的哨兵模式以及Redis集群都能够实现高可用 5、服务降级如果在高可用的情况下，缓存服务还是无情的挂掉了，这时候可以通过服务熔断和降级技术，返回预设值，阻止大量请求到数据库。这里推荐使用Hytrix。 缓存击穿缓存击穿是指由于某个缓存Key的失效，造成大量并发请求直接到数据库，造成数据库的压力。缓存击穿是针对热点Key的，只有热点Key才能在同一时间造成大量并发访问。它与缓存雪崩的区别是，缓存击穿是针对单个热点Key来说，而缓存雪崩是针对大量Key的失效。 解决方案：1、加分布式锁加载数据的时候可以利用分布式锁锁住这个数据的Key，对于获取到这个锁的线程，查询数据库更新缓存，其他线程采取重试策略，这样数据库不会同时受到很多线程访问同一条数据。这种方式能够保证缓存重建过程中数据的一致性，但会造成大量线程阻塞，影响系统QPS，对于并发不大的系统来说可以采用。 2、永不过期从缓存层面来看，不设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物理”不过期。从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，对Key加更新锁，并使用单独的线程去构建缓存。 3、二级缓存由于缓存击穿可以看作特殊的缓存雪崩，因此二级缓存机制同样能够解决部分缓存击穿问题。 参考资料：https://juejin.im/post/5aa8d3d9f265da2392360a37https://blog.csdn.net/bitcarmanlee/article/details/78635217https://juejin.im/post/5b849878e51d4538c77a974a]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis是单线程的为何速度这么快]]></title>
    <url>%2F2019%2F01%2F09%2FRedis%E6%98%AF%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%BA%E4%BD%95%E9%80%9F%E5%BA%A6%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[前言Redis是当前最为常用的缓存应用，是一款基于内存操作的Key-Values数据库,它具备读写性能高、支持丰富数据类型等优点。接下来我们探讨一下Redis为什么这么快以及为什么Redis是单线程的？ Redis到底有多快Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差！有兴趣的可以参考官方的基准程序测试《How fast is Redis？（https://redis.io/topics/benchmarks） 横轴是连接数，纵轴是QPS。 Redis为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；具体可参考https://juejin.im/post/5bc672296fb9a05cee1e11f2 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用 I/O 多路复用模型，非阻塞IO；（下面会简单描述一下） 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； I/O 多路复用模型多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用I/O 多路复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗）。redis基于Reactor模式开发事件处理器，配合I/O多路复用 文件事件：套接字操作的抽象 I/O多路复用程序：同时监听多个套接字，并向事件分派器传送事件。 文件事件分派器：接收套接字，根据事件类型调用相应的事件处理器 事件处理器：不同的函数实现不同的事件 为什么Redis是单线程的我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。 可以参考：https://redis.io/topics/faq 但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！注意：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究）；例如我在测试服务器上查看Redis进程，然后找到该进程下的线程： ps命令的“-T”参数表示显示线程（Show threads, possibly with SPID column.）“SID”栏表示线程ID，而“CMD”栏则显示了线程名称。可以看到Redis Server有多个线程在运行。 参考资料： https://blog.csdn.net/chenyao1994/article/details/79491337 https://redis.io/topics/benchmarks https://juejin.im/post/5bc672296fb9a05cee1e11f2 https://juejin.im/post/5c15048bf265da61223a3c29 https://studygolang.com/articles/10577]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Eureka原理详解]]></title>
    <url>%2F2018%2F12%2F24%2FSpring-Cloud-Eureka%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[传统的单体平台架构会随着业务发展而变得越来越臃肿，越来越难维护，这时候微服务架构应运而生，他的理念是将庞大的单体应用进行功能拆分，形成多个微服务，各个服务间都是独立解构的，从而解决单体应用在团队开发、维护上的问题。目前，微服务架构已经广泛应用在互联网行业。在微服务框架上，Spring Cloud 可以说是当前最为流行的框架。Spring Cloud 包含了一整套的组件，涵盖微服务框架上的各个方面。由于Spring Cloud 的使用在网上都有较为全面的教程，因此，本文重点讲解常用组件的原理。为了避免读者觉得枯燥，我就从典型的电商场景来讲。 业务场景假设我们要开发一个电商平台，可以实现用户下单支付并且发货的功能。那么我们需要有一个订单服务，支付服务，库存服务、仓储服务、积分服务（实际电商平台肯定不止这几个哈），下定支付的业务流程是这样的： 查询库存服务获取商品库存 商品有库存，去订单服务下订单 下定成功后，支付服务执行支付 支付完成后，订单服务、库存服务更新状态 积分服务完成相应功能 仓储服务执行发货 Spring Cloud Eureka在上面的业务场景中，假如支付服务完成相关操作后，想要调用订单服务，库存服务执行相关更新操作，该如何调用呢？我们连订单服务、库存服务的地址都不知道。这时候，就需要用到服务注册中心了。在微服务框架中，最为重要的莫过于服务注册中心，可以理解为它是所有服务的中枢，负责服务的注册及服务间发现。有了它，微服务间才能够互相访问。而在Spring Cloud Eureka就是这样一个核心组件。 服务注册在Spring Cloud的服务治理框架中，每个服务都有一个Eureka Client组件，他们通过Rest请求的方式向注册中心Eureka Server进行注册，并将自己的服务名、主机ip、端口号等一些信息发送给注册中心，注册中心再按服务名分类组织并维护服务清单。服务在注册后，注册中心会维护一个注册表，那注册表究竟是怎么样的呢？接下来我们就看看源码 1234567public abstract class AbstractInstanceRegistry implements InstanceRegistry &#123; private static final Logger logger = LoggerFactory.getLogger(AbstractInstanceRegistry.class); private static final String[] EMPTY_STR_ARRAY = new String[0]; private final ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt; registry = new ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt;(); ... 可以看到，如上图所示，图中这个名字叫做registry的CocurrentHashMap，就是注册表的核心结构。不了解CocurrentHashMap的话可以查看Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析，从代码中可以看到，Eureka Server的注册表直接基于纯内存，即在内存里维护了一个数据结构。各个服务的注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表。维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这是Eureka Server非常核心的一个点。搞清楚了这个，咱们再来分析一下registry这个东西的数据结构. 首先，这个ConcurrentHashMap的key就是服务名称，比如“inventory-service”，就是一个服务名称。 value则代表了一个服务的多个服务实例。 举例：“inventory-service”是可以有3个服务实例的，每个服务实例部署在一台机器上。 再来看看作为value的这个Map：Map&lt;String, Lease&gt;这个Map的key就是服务实例的idvalue是一个叫做Lease的类，它的泛型是一个叫做InstanceInfo的东东首先说下InstanceInfo，这个InstanceInfo是什么呢？ 12345678910111213141516171819202122public class InstanceInfo &#123; ... public static final int DEFAULT_PORT = 7001; public static final int DEFAULT_SECURE_PORT = 7002; public static final int DEFAULT_COUNTRY_ID = 1; // US // The (fixed) instanceId for this instanceInfo. This should be unique within the scope of the appName. private volatile String instanceId; private volatile String appName; @Auto private volatile String appGroupName; private volatile String ipAddr; private static final String SID_DEFAULT = "na"; @Deprecated private volatile String sid = SID_DEFAULT; private volatile int port = DEFAULT_PORT; private volatile int securePort = DEFAULT_SECURE_PORT; ... 通过源码可以看到，这个InstanceInfo就代表了服务实例的详细信息，比如实例id、ip地址、端口号等。而这个Lease，里面则会维护每个服务的注册时间、启动时间以及最近一次的服务续约时间（也就是发送心跳的时间） 服务获取假如订单服务或者仓储服务有一台机器奔溃了，那么如果后续继续向那台机器调用服务的话，肯定会失败的。要避免这种情况就必须要定时更新各个服务的清单，保证服务清单中的机器都是健康的。在Eureka中，每个注册到注册中心的Eureka Client都需要定时向Eureka Server发送Rest请求，获取全量的服务清单。 如果想要定时获取服务，必须保证Eureka Client中的eureka.client.fetch-registery = true，该值默认为true 如果希望修改缓存清单的更新时间，可通过修改Eureka Client中的eureka.client.registry-fetch-interval-seconds参数，默认值为30秒 说到服务获取，可以还得再提一下Eureka Server的在服务清单获取上的多级缓存机制，这是为了提高并发访问性能而设计的。 一级缓存ReadOnlyCacheMap，通过ConcurrentMapl来实现。通过定时任务，根据时间间隔responseCacheUpdateIntervalMs(默认为30秒)从ReadWriteCacheMap中加载新数据 1234567public class ResponseCacheImpl implements ResponseCache &#123; ...... private final ConcurrentMap&lt;Key, Value&gt; readOnlyCacheMap = new ConcurrentHashMap&lt;Key, Value&gt;(); private final LoadingCache&lt;Key, Value&gt; readWriteCacheMap; ...... 二级缓存ReadWriteCacheMap,通过Google的Gauva cache来实现。同样是通过定时任务，根据时间间隔responseCacheAutoExpirationInSeconds(默认为180秒)从上文讲到的registry中获取最新数据 1234567891011121314151617181920212223242526272829303132333435363738public class ResponseCacheImpl implements ResponseCache &#123; ...... private final LoadingCache&lt;Key, Value&gt; readWriteCacheMap; ...... ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) &#123; this.serverConfig = serverConfig; this.serverCodecs = serverCodecs; this.shouldUseReadOnlyResponseCache = serverConfig.shouldUseReadOnlyResponseCache(); this.registry = registry; long responseCacheUpdateIntervalMs = serverConfig.getResponseCacheUpdateIntervalMs(); this.readWriteCacheMap = CacheBuilder.newBuilder().initialCapacity(serverConfig.getInitialCapacityOfResponseCache()) .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(), TimeUnit.SECONDS) .removalListener(new RemovalListener&lt;Key, Value&gt;() &#123; @Override public void onRemoval(RemovalNotification&lt;Key, Value&gt; notification) &#123; Key removedKey = notification.getKey(); if (removedKey.hasRegions()) &#123; Key cloneWithNoRegions = removedKey.cloneWithoutRegions(); regionSpecificKeys.remove(cloneWithNoRegions, removedKey); &#125; &#125; &#125;) .build(new CacheLoader&lt;Key, Value&gt;() &#123; @Override public Value load(Key key) throws Exception &#123; if (key.hasRegions()) &#123; Key cloneWithNoRegions = key.cloneWithoutRegions(); regionSpecificKeys.put(cloneWithNoRegions, key); &#125; Value value = generatePayload(key); return value; &#125; &#125;); ...... 客户端拉取注册表： 首先从ReadOnlyCacheMap里查缓存的注册表 如果没有，就找ReadWriteCacheMap里缓存的注册表 如果还是没有，则会触发Gauva缓存的CacheLoader.load()方法，主要执行了generatePayload()方法从registry拉取数据并写入到ReadWriteCacheMap中 获取到数据后，写入ReadOnlyCacheMap中并返回 服务续约服务提供者在注册完服务后，需要维护一个心跳用来持续告诉Eureka Server我还活着，防止Eureka Server将该服务实例从可用服务列表中剔除，该动作就叫做服务续约。关于服务续约有两个重要属性（Eureka Client配置）： eureka.instance.lease-renewal-interval-in-seconds，用于定义服务续约的调用间隔时间，也就是定时发送心跳的时间，默认为30秒 eureka.instance.lease-expiration-duration-in-seconds，用于定义服务失效的时间，超过该时间没有发送心跳给Eureka Server，就会将该服务从服务列表剔除，默认为90秒 Eureka Server在启动之后会创建一个定时任务，每隔一段时间（默认为60秒）将当前服务注册表中超时（默认为90秒）没有续约的服务剔除。 接下来我们从源码中来了解服务续约的实现机制：12345678910111213141516171819202122232425@Singletonpublic class DiscoveryClient implements EurekaClient &#123; ...... private void initScheduledTasks() &#123; ...... //判断是否应该向Eureka Server注册 if (clientConfig.shouldRegisterWithEureka()) &#123; int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info("Starting heartbeat executor: " + "renew interval is: &#123;&#125;", renewalIntervalInSecs); // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( "heartbeat", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); ......&#125; 服务续约任务的初始化在DicoveryClient中，可以看到，调度线程池、续约线程池、续约间隔、HeartbeatThread全部封装在了TimedSupervisorTask中，TimedSupervisorTask相当于一个包装类或调度类，封装了续约所需要的全部信息。TimedSupervisorTask内部实现了Runnable接口。1234567891011121314151617181920212223242526272829303132333435363738394041@Singletonpublic class DiscoveryClient implements EurekaClient &#123; ...... /** * The heartbeat task that renews the lease in the given intervals. */ private class HeartbeatThread implements Runnable &#123; public void run() &#123; if (renew()) &#123; lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis(); &#125; &#125; &#125; ...... /** * Renew with the eureka service by making the appropriate REST call */ boolean renew() &#123; EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(PREFIX + "&#123;&#125; - Heartbeat status: &#123;&#125;", appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) &#123; REREGISTER_COUNTER.increment(); logger.info(PREFIX + "&#123;&#125; - Re-registering apps/&#123;&#125;", appPathIdentifier, instanceInfo.getAppName()); long timestamp = instanceInfo.setIsDirtyWithTime(); boolean success = register(); if (success) &#123; instanceInfo.unsetIsDirty(timestamp); &#125; return success; &#125; return httpResponse.getStatusCode() == Status.OK.getStatusCode(); &#125; catch (Throwable e) &#123; logger.error(PREFIX + "&#123;&#125; - was unable to send heartbeat!", appPathIdentifier, e); return false; &#125; &#125; ......&#125; 续约的具体执行逻辑在renew()方法中，实现较为简单，就是通过Rest请求向Eureka Server发送心跳。 参考资料: https://juejin.im/post/5be13b83f265da6116393fc7 https://juejin.im/post/5be3f8dcf265da613a5382ca https://blog.csdn.net/u012394095/article/details/80894140 《Spring Cloud微服务实战》-翟永超著]]></content>
      <categories>
        <category>Spring Cloud</category>
      </categories>
      <tags>
        <tag>Spring Cloud</tag>
        <tag>Eureka</tag>
        <tag>微服务</tag>
        <tag>注册中心</tag>
      </tags>
  </entry>
</search>
